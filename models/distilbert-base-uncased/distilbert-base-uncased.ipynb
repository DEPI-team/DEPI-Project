{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tf-keras transformers sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abdoh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"KevinJuanC/MovieRecommendationSystem\")\n",
    "model = AutoModel.from_pretrained(\"KevinJuanC/MovieRecommendationSystem\")\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv(r\"D:\\abdo\\AI\\projects\\recommender\\needed features\\movies_with_tags_rating.csv\") # ensure the right path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean movie titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_movie_title(title):\n",
    "    title = str(title)\n",
    "    title = title.lower()\n",
    "    title = re.sub(r'\\s*\\(.*?\\)\\s*', '', title)\n",
    "    return title.strip()\n",
    "\n",
    "# Apply title cleaning to the dataset\n",
    "df['cleaned_title'] = df['title'].apply(clean_movie_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract embeddings using DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract embeddings using DistilBERT for different features\n",
    "def get_feature_embedding(feature):\n",
    "    if pd.isna(feature) or not isinstance(feature, str):\n",
    "        return np.zeros(768)  # Return a zero vector if input is NaN or not a string\n",
    "\n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer(\n",
    "        feature,\n",
    "        return_tensors=\"pt\",    # Return PyTorch tensors\n",
    "        truncation=True,         # Automatically truncate to the max length\n",
    "        max_length=512,          # Maximum length of tokens\n",
    "        padding=\"max_length\"     # Pad to the max length if necessary\n",
    "    )\n",
    "    \n",
    "    # Pass the inputs through the model to get embeddings\n",
    "    with torch.no_grad():  # Disable gradient calculations for inference\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Use the mean of the last hidden state to represent the embedding\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy()\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract embeddings for all movie features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverview_embedding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverview\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(get_feature_embedding)\n\u001b[0;32m      2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenre_embedding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenre\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(get_feature_embedding)\n\u001b[0;32m      3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcast_embedding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcast\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(get_feature_embedding)\n",
      "File \u001b[1;32mc:\\Users\\abdoh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4521\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4525\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4526\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4527\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4528\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4628\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\u001b[38;5;28mself\u001b[39m, func, convert_dtype, args, kwargs)\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32mc:\\Users\\abdoh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\abdoh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmap_infer(\n\u001b[0;32m   1077\u001b[0m             values,\n\u001b[0;32m   1078\u001b[0m             f,\n\u001b[0;32m   1079\u001b[0m             convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype,\n\u001b[0;32m   1080\u001b[0m         )\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\abdoh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[5], line 17\u001b[0m, in \u001b[0;36mget_feature_embedding\u001b[1;34m(feature)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Pass the inputs through the model to get embeddings\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# Disable gradient calculations for inference\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Use the mean of the last hidden state to represent the embedding\u001b[39;00m\n\u001b[0;32m     20\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\abdoh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\abdoh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\abdoh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:703\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    701\u001b[0m         attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(input_shape, device\u001b[38;5;241m=\u001b[39mdevice)  \u001b[38;5;66;03m# (bs, seq_length)\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(\n\u001b[0;32m    704\u001b[0m     x\u001b[38;5;241m=\u001b[39membeddings,\n\u001b[0;32m    705\u001b[0m     attn_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    706\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m    707\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    708\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m    709\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m    710\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\abdoh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\abdoh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\abdoh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:464\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    456\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    457\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    458\u001b[0m         hidden_state,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    461\u001b[0m         output_attentions,\n\u001b[0;32m    462\u001b[0m     )\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 464\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m    465\u001b[0m         hidden_state,\n\u001b[0;32m    466\u001b[0m         attn_mask,\n\u001b[0;32m    467\u001b[0m         head_mask[i],\n\u001b[0;32m    468\u001b[0m         output_attentions,\n\u001b[0;32m    469\u001b[0m     )\n\u001b[0;32m    471\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32mc:\\Users\\abdoh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\abdoh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\abdoh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:408\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    405\u001b[0m sa_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msa_layer_norm(sa_output \u001b[38;5;241m+\u001b[39m x)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;66;03m# Feed Forward Network\u001b[39;00m\n\u001b[1;32m--> 408\u001b[0m ffn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn(sa_output)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    409\u001b[0m ffn_output: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer_norm(ffn_output \u001b[38;5;241m+\u001b[39m sa_output)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    411\u001b[0m output \u001b[38;5;241m=\u001b[39m (ffn_output,)\n",
      "File \u001b[1;32mc:\\Users\\abdoh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\abdoh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\abdoh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:343\u001b[0m, in \u001b[0;36mFFN.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m apply_chunking_to_forward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mff_chunk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_size_feed_forward, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len_dim, \u001b[38;5;28minput\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\abdoh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\pytorch_utils.py:239\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m forward_fn(\u001b[38;5;241m*\u001b[39minput_tensors)\n",
      "File \u001b[1;32mc:\\Users\\abdoh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:348\u001b[0m, in \u001b[0;36mFFN.ff_chunk\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    346\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin1(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    347\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(x)\n\u001b[1;32m--> 348\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin2(x)\n\u001b[0;32m    349\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\abdoh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\abdoh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\abdoh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df['overview_embedding'] = df['overview'].apply(get_feature_embedding)\n",
    "df['genre_embedding'] = df['genre'].apply(get_feature_embedding)\n",
    "df['cast_embedding'] = df['cast'].apply(get_feature_embedding)\n",
    "df['director_embedding'] = df['director'].apply(get_feature_embedding)\n",
    "\n",
    "\n",
    "# Step 4: Create an embedding matrix for each feature\n",
    "overview_embedding_matrix = np.stack(df['overview_embedding'].values)\n",
    "genre_embedding_matrix = np.stack(df['genre_embedding'].values)\n",
    "cast_embedding_matrix = np.stack(df['cast_embedding'].values)\n",
    "director_embedding_matrix = np.stack(df['director_embedding'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save the embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('overview_embedding_matrix.npy', overview_embedding_matrix)\n",
    "np.save('genre_embedding_matrix.npy', genre_embedding_matrix)\n",
    "np.save('cast_embedding_matrix.npy', cast_embedding_matrix)\n",
    "np.save('director_embedding_matrix.npy', director_embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combining features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_embeddings(*embeddings):\n",
    "    return np.mean(embeddings, axis=0)\n",
    "\n",
    "# Step 5: Generate a combined embedding\n",
    "df['combined_embedding'] = df.apply(\n",
    "    lambda row: combine_embeddings(\n",
    "        row['overview_embedding'],\n",
    "        row['genre_embedding'],\n",
    "        row['cast_embedding'],\n",
    "        row['director_embedding']\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "combined_embedding_matrix = np.stack(df['combined_embedding'].values)\n",
    "\n",
    "np.save('combined_embedding_matrix.npy', combined_embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the embedding matrix if  it exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_embedding_matrix = np.load('overview_embedding_matrix.npy')\n",
    "genre_embedding_matrix = np.load('genre_embedding_matrix.npy')\n",
    "cast_embedding_matrix = np.load('cast_embedding_matrix.npy')\n",
    "director_embedding_matrix = np.load('director_embedding_matrix.npy')\n",
    "combined_embedding_matrix = np.load('combined_embedding_matrix.npy')\n",
    "\n",
    "df['overview_embedding'] = list(overview_embedding_matrix)\n",
    "df['genre_embedding'] = list(genre_embedding_matrix)\n",
    "df['cast_embedding'] = list(cast_embedding_matrix)\n",
    "df['director_embedding'] = list(director_embedding_matrix)\n",
    "df['combined_embedding'] = list(combined_embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_similar_movies(movie_title, df, feature='overview', top_n=3):\n",
    "    cleaned_movie_title = clean_movie_title(movie_title)\n",
    "    \n",
    "    if cleaned_movie_title in df['cleaned_title'].values:\n",
    "        movie_index = df[df['cleaned_title'] == cleaned_movie_title].index[0]\n",
    "        \n",
    "        # Select the correct embedding matrix based on the feature\n",
    "        if feature == 'overview':\n",
    "            input_embedding = df.loc[movie_index, 'overview_embedding']\n",
    "            embedding_matrix = overview_embedding_matrix\n",
    "        elif feature == 'genre':\n",
    "            input_embedding = df.loc[movie_index, 'genre_embedding']\n",
    "            embedding_matrix = genre_embedding_matrix\n",
    "        elif feature == 'cast':\n",
    "            input_embedding = df.loc[movie_index, 'cast_embedding']\n",
    "            embedding_matrix = cast_embedding_matrix\n",
    "        elif feature == 'director':\n",
    "            input_embedding = df.loc[movie_index, 'director_embedding']\n",
    "            embedding_matrix = director_embedding_matrix\n",
    "        elif feature == 'combined':\n",
    "            input_embedding = df.loc[movie_index, 'combined_embedding']\n",
    "            embedding_matrix = combined_embedding_matrix\n",
    "        else:\n",
    "            print(\"Invalid feature specified.\")\n",
    "            return None\n",
    "        \n",
    "        # Compute cosine similarity and sort similar movies\n",
    "        similarities = cosine_similarity([input_embedding], embedding_matrix)[0]\n",
    "        similar_movies = df.iloc[np.argsort(similarities)[::-1][1:top_n+1]]\n",
    "        return similar_movies[['title', 'genre', 'rating']]\n",
    "    else:\n",
    "        print(f\"Movie '{movie_title}' not found in the dataset.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie 'me before you' not found in the dataset.\n",
      "Movie 'me before you' not found in the dataset.\n",
      "Movie 'me before you' not found in the dataset.\n",
      "Movie 'me before you' not found in the dataset.\n",
      "Movie 'me before you' not found in the dataset.\n",
      "Movies similar to me before you based on Overview:\n",
      "\n",
      "Movies similar to me before you  based on Genre:\n",
      "\n",
      "Movies similar to me before you  based on Cast:\n",
      "\n",
      "Movies similar to me before you  based on Director:\n",
      "\n",
      "Movies similar to me before you  based on Combined Features:\n"
     ]
    }
   ],
   "source": [
    "test = input('enter your favourite movie: ')\n",
    "\n",
    "recommended_movies_overview = recommend_similar_movies(test, df, feature='overview', top_n=3)\n",
    "recommended_movies_genre = recommend_similar_movies(test , df, feature='genre', top_n=3)\n",
    "recommended_movies_cast = recommend_similar_movies(test, df, feature='cast', top_n=3)\n",
    "recommended_movies_director = recommend_similar_movies(test, df, feature='director', top_n=3)\n",
    "recommended_movies_combined = recommend_similar_movies(test, df, feature='combined', top_n=3)\n",
    "\n",
    "\n",
    "print(f\"Movies similar to {test} based on Overview:\")\n",
    "if recommended_movies_overview is not None:\n",
    "    print(recommended_movies_overview)\n",
    "\n",
    "print(f\"\\nMovies similar to {test}  based on Genre:\")\n",
    "if recommended_movies_genre is not None:\n",
    "    print(recommended_movies_genre)\n",
    "\n",
    "print(f\"\\nMovies similar to {test}  based on Cast:\")\n",
    "if recommended_movies_cast is not None:\n",
    "    print(recommended_movies_cast)\n",
    "\n",
    "print(f\"\\nMovies similar to {test}  based on Director:\")\n",
    "if recommended_movies_director is not None:\n",
    "    print(recommended_movies_director)\n",
    "\n",
    "print(f\"\\nMovies similar to {test}  based on Combined Features:\")\n",
    "if recommended_movies_combined is not None:\n",
    "    print(recommended_movies_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abdoh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies similar to inception based on Overview:\n",
      "              title                                       genre  rating\n",
      "8431   The Mechanic                     Action, Crime, Thriller    3.25\n",
      "4680  Our Man Flint  Action, Adventure, Comedy, Fantasy, Sci-Fi    3.20\n",
      "4497      Hopscotch                           Adventure, Comedy    3.55\n",
      "\n",
      "Movies similar to inception  based on Genre:\n",
      "             title                                genre  rating\n",
      "1199        Aliens  Action, Adventure, Sci-Fi, Thriller     4.2\n",
      "2075  The Avengers  Action, Adventure, Sci-Fi, Thriller     1.9\n",
      "2077  The Avengers  Action, Adventure, Sci-Fi, Thriller     4.0\n",
      "\n",
      "Movies similar to inception  based on Cast:\n",
      "                           title                                genre  rating\n",
      "3066                   The Beach  Adventure, Drama, Romance, Thriller    3.30\n",
      "2467  10 Things I Hate About You               Comedy, Drama, Romance    3.65\n",
      "8082          500 Days of Summer               Comedy, Drama, Romance    3.85\n",
      "\n",
      "Movies similar to inception  based on Director:\n",
      "                       title                                  genre  rating\n",
      "8652   The Dark Knight Rises                Action, Drama, Thriller    4.20\n",
      "10428                Dunkirk  Action, Drama, History, Thriller, War    3.90\n",
      "9234            Interstellar               Adventure, Drama, Sci-Fi    4.35\n",
      "\n",
      "Movies similar to inception  based on Combined Features:\n",
      "             title                             genre  rating\n",
      "7241  The Prestige  Drama, Mystery, Sci-Fi, Thriller    4.25\n",
      "9234  Interstellar          Adventure, Drama, Sci-Fi    4.35\n",
      "3723       Memento                 Mystery, Thriller    4.20\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv(r\"D:\\abdo\\AI\\projects\\recommender\\needed features\\movies_with_tags_rating.csv\")\n",
    "\n",
    "# Step 2: Initialize a DistilBERT model and tokenizer\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Function to clean movie titles\n",
    "def clean_movie_title(title):\n",
    "    title = str(title)\n",
    "    title = title.lower()\n",
    "    title = re.sub(r'\\s*\\(.*?\\)\\s*', '', title)\n",
    "    return title.strip()\n",
    "\n",
    "# Apply title cleaning to the dataset\n",
    "df['cleaned_title'] = df['title'].apply(clean_movie_title)\n",
    "\n",
    "# Function to extract embeddings using DistilBERT for different features\n",
    "def get_feature_embedding(feature):\n",
    "    if pd.isna(feature) or not isinstance(feature, str):\n",
    "        return np.zeros(768)  # Return a zero vector if input is NaN or not a string\n",
    "\n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer(\n",
    "        feature,\n",
    "        return_tensors=\"pt\",    # Return PyTorch tensors\n",
    "        truncation=True,         # Automatically truncate to the max length\n",
    "        max_length=512,          # Maximum length of tokens\n",
    "        padding=\"max_length\"     # Pad to the max length if necessary\n",
    "    )\n",
    "    \n",
    "    # Pass the inputs through the model to get embeddings\n",
    "    with torch.no_grad():  # Disable gradient calculations for inference\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Use the mean of the last hidden state to represent the embedding\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy()\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "\"\"\"\n",
    "# Step 3: Extract embeddings for all movie features\n",
    "df['overview_embedding'] = df['overview'].apply(get_feature_embedding)\n",
    "df['genre_embedding'] = df['genre'].apply(get_feature_embedding)\n",
    "df['cast_embedding'] = df['cast'].apply(get_feature_embedding)\n",
    "df['director_embedding'] = df['director'].apply(get_feature_embedding)\n",
    "\n",
    "# Step 4: Create an embedding matrix for each feature\n",
    "overview_embedding_matrix = np.stack(df['overview_embedding'].values)\n",
    "genre_embedding_matrix = np.stack(df['genre_embedding'].values)\n",
    "cast_embedding_matrix = np.stack(df['cast_embedding'].values)\n",
    "director_embedding_matrix = np.stack(df['director_embedding'].values)\n",
    "\n",
    "\n",
    "# Function to combine multiple embeddings (e.g., averaging)\n",
    "def combine_embeddings(*embeddings):\n",
    "    return np.mean(embeddings, axis=0)\n",
    "\n",
    "# Step 5: Generate a combined embedding\n",
    "df['combined_embedding'] = df.apply(\n",
    "    lambda row: combine_embeddings(\n",
    "        row['overview_embedding'],\n",
    "        row['genre_embedding'],\n",
    "        row['cast_embedding'],\n",
    "        row['director_embedding']\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "overview_embedding_matrix=np.load('overview_embedding_matrix.npy')\n",
    "\n",
    "genre_embedding_matrix=np.load('genre_embedding_matrix.npy')\n",
    "\n",
    "cast_embedding_matrix=np.load('cast_embedding_matrix.npy')\n",
    "\n",
    "director_embedding_matrix=np.load('director_embedding_matrix.npy')\n",
    "\n",
    "combined_embedding_matrix=np.load('combined_embedding_matrix.npy')\n",
    "\n",
    "df['overview_embedding'] = list(overview_embedding_matrix)\n",
    "df['genre_embedding'] = list(genre_embedding_matrix)\n",
    "df['cast_embedding'] = list(cast_embedding_matrix)\n",
    "df['director_embedding'] = list(director_embedding_matrix)\n",
    "df['combined_embedding'] = list(combined_embedding_matrix)\n",
    "\n",
    "\n",
    "# Function to recommend similar movies based on a specified feature or combined features\n",
    "def recommend_similar_movies(movie_title, df, feature='overview', top_n=3):\n",
    "    cleaned_movie_title = clean_movie_title(movie_title)\n",
    "    \n",
    "    if cleaned_movie_title in df['cleaned_title'].values:\n",
    "        movie_index = df[df['cleaned_title'] == cleaned_movie_title].index[0]\n",
    "        \n",
    "        # Select the correct embedding matrix based on the feature\n",
    "        if feature == 'overview':\n",
    "            input_embedding = df.loc[movie_index, 'overview_embedding']\n",
    "            embedding_matrix = overview_embedding_matrix\n",
    "        elif feature == 'genre':\n",
    "            input_embedding = df.loc[movie_index, 'genre_embedding']\n",
    "            embedding_matrix = genre_embedding_matrix\n",
    "        elif feature == 'cast':\n",
    "            input_embedding = df.loc[movie_index, 'cast_embedding']\n",
    "            embedding_matrix = cast_embedding_matrix\n",
    "        elif feature == 'director':\n",
    "            input_embedding = df.loc[movie_index, 'director_embedding']\n",
    "            embedding_matrix = director_embedding_matrix\n",
    "        elif feature == 'combined':\n",
    "            input_embedding = df.loc[movie_index, 'combined_embedding']\n",
    "            embedding_matrix = combined_embedding_matrix\n",
    "        else:\n",
    "            print(\"Invalid feature specified.\")\n",
    "            return None\n",
    "        \n",
    "        # Compute cosine similarity and sort similar movies\n",
    "        similarities = cosine_similarity([input_embedding], embedding_matrix)[0]\n",
    "        similar_movies = df.iloc[np.argsort(similarities)[::-1][1:top_n+1]]\n",
    "        return similar_movies[['title', 'genre', 'rating']]\n",
    "    else:\n",
    "        print(f\"Movie '{movie_title}' not found in the dataset.\")\n",
    "        return None\n",
    "\n",
    "test = \"inception\"\n",
    "# Example: Recommend movies similar to 'Interstellar' based on different features\n",
    "recommended_movies_overview = recommend_similar_movies(test, df, feature='overview', top_n=3)\n",
    "recommended_movies_genre = recommend_similar_movies(test , df, feature='genre', top_n=3)\n",
    "recommended_movies_cast = recommend_similar_movies(test, df, feature='cast', top_n=3)\n",
    "recommended_movies_director = recommend_similar_movies(test, df, feature='director', top_n=3)\n",
    "recommended_movies_combined = recommend_similar_movies(test, df, feature='combined', top_n=3)\n",
    "\n",
    "# Display recommendations\n",
    "print(f\"Movies similar to {test} based on Overview:\")\n",
    "if recommended_movies_overview is not None:\n",
    "    print(recommended_movies_overview)\n",
    "\n",
    "print(f\"\\nMovies similar to {test}  based on Genre:\")\n",
    "if recommended_movies_genre is not None:\n",
    "    print(recommended_movies_genre)\n",
    "\n",
    "print(f\"\\nMovies similar to {test}  based on Cast:\")\n",
    "if recommended_movies_cast is not None:\n",
    "    print(recommended_movies_cast)\n",
    "\n",
    "print(f\"\\nMovies similar to {test}  based on Director:\")\n",
    "if recommended_movies_director is not None:\n",
    "    print(recommended_movies_director)\n",
    "\n",
    "print(f\"\\nMovies similar to {test}  based on Combined Features:\")\n",
    "if recommended_movies_combined is not None:\n",
    "    print(recommended_movies_combined)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## handling unadded movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abdoh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie 'me before you' not found in the dataset. Fetching recommendations from TMDb...\n",
      "\n",
      "Top 3 movies similar to 'me before you' based on TMDb:\n",
      "           title         genre  rating\n",
      "       Priehrada         Drama   2.000\n",
      "      Blood Knot         Drama   0.000\n",
      "Summer in Berlin Comedy, Drama   6.557\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import requests\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r\"D:\\abdo\\AI\\projects\\recommender\\needed features\\movies_with_tags_rating.csv\")\n",
    "\n",
    "# Initialize DistilBERT model and tokenizer\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Clean movie titles\n",
    "def clean_movie_title(title):\n",
    "    return re.sub(r'\\s*\\(.*?\\)\\s*', '', str(title).lower()).strip()\n",
    "\n",
    "# Apply title cleaning to the dataset\n",
    "df['cleaned_title'] = df['title'].apply(clean_movie_title)\n",
    "\n",
    "# Load precomputed embedding matrices\n",
    "embedding_features = ['overview', 'genre', 'cast', 'director', 'combined']\n",
    "for feature in embedding_features:\n",
    "    matrix = np.load(f'{feature}_embedding_matrix.npy')\n",
    "    df[f'{feature}_embedding'] = list(matrix)\n",
    "\n",
    "# Fetch similar movies from TMDb\n",
    "def fetch_tmdb_recommendations(movie_title):\n",
    "    api_key = \"ddad317e776c8ec2f92ec52efe9d34f5\"  \n",
    "    search_response = requests.get(f\"https://api.themoviedb.org/3/search/movie?api_key={api_key}&query={movie_title}\").json()\n",
    "\n",
    "    if 'results' in search_response and search_response['results']:\n",
    "        movie_id = search_response['results'][0]['id']\n",
    "        recommendations_response = requests.get(f\"https://api.themoviedb.org/3/movie/{movie_id}/similar?api_key={api_key}\").json()\n",
    "\n",
    "        genres_response = requests.get(f\"https://api.themoviedb.org/3/genre/movie/list?api_key={api_key}\").json()\n",
    "        genre_mapping = {genre['id']: genre['name'] for genre in genres_response['genres']}\n",
    "        \n",
    "        similar_movies = []\n",
    "        for movie in recommendations_response['results']:\n",
    "            movie_genres = [genre_mapping.get(genre_id, \"Unknown\") for genre_id in movie['genre_ids']]\n",
    "            similar_movies.append({\n",
    "                'title': movie['title'],\n",
    "                'genre': ', '.join(movie_genres),\n",
    "                'rating': movie.get('vote_average', 'N/A')\n",
    "            })\n",
    "        \n",
    "        similar_movies_df = pd.DataFrame(similar_movies)\n",
    "\n",
    "        # Get the top 3 movies\n",
    "        top_movies_df = similar_movies_df.head(3)\n",
    "\n",
    "        return top_movies_df\n",
    "    \n",
    "    print(f\"No results found for '{movie_title}' in TMDb. Response: {search_response}\")\n",
    "    return None\n",
    "\n",
    "# Recommend similar movies\n",
    "def recommend_similar_movies(movie_title, df, feature='overview', top_n=3):\n",
    "    cleaned_movie_title = clean_movie_title(movie_title)\n",
    "\n",
    "    if cleaned_movie_title in df['cleaned_title'].values:\n",
    "        movie_index = df[df['cleaned_title'] == cleaned_movie_title].index[0]\n",
    "\n",
    "        # Recommend based on different features\n",
    "        features = ['overview', 'genre', 'cast', 'director', 'combined']\n",
    "        for feature in features:\n",
    "            input_embedding = df.loc[movie_index, f'{feature}_embedding']\n",
    "            embedding_matrix = np.stack(df[f'{feature}_embedding'].values)\n",
    "\n",
    "            similarities = cosine_similarity([input_embedding], embedding_matrix)[0]\n",
    "            similar_movies = df.iloc[np.argsort(similarities)[::-1][1:top_n+1]]\n",
    "            print(f\"\\nMovies similar to {movie_title} based on {feature.capitalize()}:\")\n",
    "            print(similar_movies[['title', 'genre', 'rating']].to_string(index=False))\n",
    "        \n",
    "    else:\n",
    "        print(f\"Movie '{movie_title}' not found in the dataset. Fetching recommendations from TMDb...\")\n",
    "        recommendations = fetch_tmdb_recommendations(movie_title)\n",
    "        if recommendations is not None and not recommendations.empty:\n",
    "            print(f\"\\nTop 3 movies similar to '{movie_title}' based on TMDb:\")\n",
    "            print(recommendations.to_string(index=False))\n",
    "        else:\n",
    "            print(f\"No recommendations found for '{movie_title}' in TMDb.\")\n",
    "\n",
    "# Test the recommendation system\n",
    "test_movie = input('enter your favourite movie: ')\n",
    "recommend_similar_movies(test_movie, df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
