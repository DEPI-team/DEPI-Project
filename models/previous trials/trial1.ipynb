{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T12:58:28.042997Z","iopub.status.busy":"2024-09-17T12:58:28.042575Z","iopub.status.idle":"2024-09-17T12:58:47.415212Z","shell.execute_reply":"2024-09-17T12:58:47.413583Z","shell.execute_reply.started":"2024-09-17T12:58:28.042955Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting imdbPY\n","  Downloading IMDbPY-2022.7.9-py3-none-any.whl.metadata (498 bytes)\n","Collecting cinemagoer (from imdbPY)\n","  Downloading cinemagoer-2023.5.1-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: SQLAlchemy in /opt/conda/lib/python3.10/site-packages (from cinemagoer->imdbPY) (2.0.30)\n","Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from cinemagoer->imdbPY) (5.3.0)\n","Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy->cinemagoer->imdbPY) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy->cinemagoer->imdbPY) (3.0.3)\n","Downloading IMDbPY-2022.7.9-py3-none-any.whl (1.2 kB)\n","Downloading cinemagoer-2023.5.1-py3-none-any.whl (297 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.2/297.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: cinemagoer, imdbPY\n","Successfully installed cinemagoer-2023.5.1 imdbPY-2022.7.9\n"]}],"source":["! pip install imdbPY"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import imdb\n","import csv\n","import pandas as pd\n","from imdb import IMDb, IMDbDataAccessError"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ia = imdb.IMDb()\n","csv_file = '/kaggle/input/imdbdata/imdb_data.csv'"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data=pd.read_csv(r'/kaggle/input/movielens/movies.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#old verison \n","import imdb\n","import csv\n","import random\n","import pandas as pd\n","import concurrent.futures\n","\n","# Load the movie data\n","imdbs = data['imdbId']\n","\n","# Set up the IMDb API\n","ia = imdb.IMDb()\n","\n","# Define the batch size for processing\n","batch_size = 100\n","\n","# Define the function to get movie data\n","def get_movie_data(movie_id):\n","    try:\n","        movie = ia.get_movie(movie_id)\n","        ia.update(movie, 'reviews')\n","        ia.update(movie, 'cast')\n","        data = {\n","            'film_name': movie.get('title', ''),\n","            'film_rate': movie.get('rating', 0.0),  # default to 0.0 if no rating\n","            'plot': movie.get('plot', ''),\n","            'cover_url': movie.get('cover url', ''),\n","            'cast': ', '.join([person['name'] for person in movie.get('cast', [])[:3]]) if movie.get('cast') else '',  # return empty string if cast is not available\n","            'reviews': movie.get('reviews', [{}])[0].get('content', '')  # default to empty string if no reviews\n","        }\n","        return data\n","    except IMDbDataAccessError as e:\n","        return {'film_name': '', 'film_rate': 0.0, 'plot': '', 'cover_url': '', 'cast': '', 'reviews': ''}  # return default values\n","    except urllib.error.HTTPError as e:\n","        return {'film_name': '', 'film_rate': 0.0, 'plot': '', 'cover_url': '', 'cast': '', 'reviews': ''}  # return default values\n","\n","# Define the function to process a batch of movie IDs\n","def process_batch(movie_ids):\n","    data_list = []\n","    for movie_id in movie_ids:\n","        data_list.append(get_movie_data(movie_id))\n","    return data_list\n","\n","# Create a list to store the processed data\n","data_list = []\n","\n","# Create a ThreadPoolExecutor to parallelize the API calls\n","with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n","    # Split the movie IDs into batches\n","    batches = [imdbs[i:i + batch_size] for i in range(0, len(imdbs), batch_size)]\n","    \n","    # Process each batch in parallel\n","    futures = [executor.submit(process_batch, batch) for batch in batches]\n","    \n","    # Collect the results\n","    for future in concurrent.futures.as_completed(futures):\n","        data_list.extend(future.result())\n","csv_file='/kaggle/input/imdbdata/imdb_data.csv'\n","# Save the processed data to a CSV file\n","with open(csv_file, 'w', newline='') as csvfile:\n","    writer = csv.writer(csvfile)\n","    writer.writerow(['film_name', 'film_rate', 'plot', 'cover_url', 'cast', 'reviews'])\n","    for data in data_list:\n","        writer.writerow(list(data.values()))"]},{"cell_type":"markdown","metadata":{},"source":["# updated version with more features "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import imdb\n","import csv\n","import random\n","import pandas as pd\n","import concurrent.futures\n","import urllib.error\n","\n","\n","# Load the movie data\n","imdbs = data['imdbId']\n","\n","# Set up the IMDb API\n","ia = imdb.IMDb()\n","\n","# Define the batch size for processing\n","batch_size = 100\n","\n","# Define the function to get movie data\n","def get_movie_data(movie_id):\n","    try:\n","        movie = ia.get_movie(movie_id)\n","        ia.update(movie, 'reviews')\n","        ia.update(movie, 'cast')\n","        ia.update(movie, 'directors')\n","        ia.update(movie, 'writers')\n","\n","        data = {\n","            'imdbId': movie_id,\n","            'film_name': movie.get('title', ''),\n","            'film_rate': movie.get('rating', 0.0),  # default to 0.0 if no rating\n","            'plot': movie.get('plot', [''])[0],  # take the first plot synopsis\n","            'cover_url': movie.get('cover url', ''),\n","            'cast': ', '.join([person['name'] for person in movie.get('cast', [])[:3]]) if movie.get('cast') else '',  # top 3 cast\n","            'reviews': movie.get('reviews', [{}])[0].get('content', ''),  # first review content\n","            'director': ', '.join([person['name'] for person in movie.get('directors', [])]) if movie.get('directors') else '',\n","            'writer': ', '.join([person.get('name', '') for person in movie.get('writers', [])]) if movie.get('writers') else '',\n","            'genre': ', '.join(movie.get('genres', [])) if movie.get('genres') else ''  # join genre list\n","        }\n","        return data\n","    except imdb.IMDbDataAccessError as e:\n","        return {'imdbId': movie_id, 'film_name': '', 'film_rate': 0.0, 'plot': '', 'cover_url': '', 'cast': '', 'reviews': '', 'director': '', 'writer': '', 'genre': ''}\n","    except urllib.error.HTTPError as e:\n","        return {'imdbId': movie_id, 'film_name': '', 'film_rate': 0.0, 'plot': '', 'cover_url': '', 'cast': '', 'reviews': '', 'director': '', 'writer': '', 'genre': ''}\n","\n","# Define the function to process a batch of movie IDs\n","def process_batch(movie_ids):\n","    data_list = []\n","    for movie_id in movie_ids:\n","        data_list.append(get_movie_data(movie_id))\n","    return data_list\n","\n","# Create a list to store the processed data\n","data_list = []\n","\n","# Create a ThreadPoolExecutor to parallelize the API calls\n","with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n","    # Split the movie IDs into batches\n","    batches = [imdbs[i:i + batch_size] for i in range(0, len(imdbs), batch_size)]\n","    \n","    # Process each batch in parallel\n","    futures = [executor.submit(process_batch, batch) for batch in batches]\n","    \n","    # Collect the results\n","    for future in concurrent.futures.as_completed(futures):\n","        data_list.extend(future.result())\n","\n","# Specify the path to save the CSV\n","csv_file = '/kaggle/input/imdbdata/imdb_data.csv'\n","\n","# Save the processed data to a CSV file\n","with open(csv_file, 'w', newline='') as csvfile:\n","    writer = csv.writer(csvfile)\n","    writer.writerow(['imdbId', 'film_name', 'film_rate', 'plot', 'cover_url', 'cast', 'reviews', 'director', 'writer', 'genre'])\n","    for data in data_list:\n","        writer.writerow([data['imdbId'], data['film_name'], data['film_rate'], data['plot'], data['cover_url'], data['cast'], data['reviews'], data['director'], data['writer'], data['genre']])\n"]},{"cell_type":"markdown","metadata":{},"source":["# missing features only "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import imdb\n","import csv\n","import pandas as pd\n","import concurrent.futures\n","import urllib.error\n","\n","imdbs = data['imdbId']\n","\n","ia = imdb.IMDb()\n","\n","batch_size = 100\n","\n","# Define the function to get movie data\n","def get_movie_data(movie_id):\n","    try:\n","        movie = ia.get_movie(movie_id)\n","        ia.update(movie, info=['directors', 'genres'])  # Only updating required fields\n","\n","        data = {\n","            'imdbId': movie_id,\n","            'film_name': movie.get('title', ''),\n","            'director': ', '.join([person['name'] for person in movie.get('directors', [])]) if movie.get('directors') else '',\n","            'genre': ', '.join(movie.get('genres', [])) if movie.get('genres') else ''\n","        }\n","        return data\n","    except imdb.IMDbDataAccessError as e:\n","        # Handle IMDb Data Access Error\n","        return {'imdbId': movie_id, 'film_name': '', 'director': '', 'genre': ''}\n","    except urllib.error.HTTPError as e:\n","        # Handle HTTP Error\n","        return {'imdbId': movie_id, 'film_name': '', 'director': '', 'genre': ''}\n","\n","# Define the function to process a batch of movie IDs\n","def process_batch(movie_ids):\n","    data_list = []\n","    for movie_id in movie_ids:\n","        data_list.append(get_movie_data(movie_id))\n","    return data_list\n","\n","# Create a list to store the processed data\n","data_list = []\n","\n","# Create a ThreadPoolExecutor to parallelize the API calls\n","with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n","    # Split the movie IDs into batches\n","    batches = [imdbs[i:i + batch_size] for i in range(0, len(imdbs), batch_size)]\n","    \n","    # Process each batch in parallel\n","    futures = [executor.submit(process_batch, batch) for batch in batches]\n","    \n","    # Collect the results\n","    for future in concurrent.futures.as_completed(futures):\n","        data_list.extend(future.result())\n","\n","# Specify the path to save the CSV\n","csv_file = '/kaggle/input/imdbdata/imdb_data.csv'\n","\n","# Save the processed data to a CSV file with only imdbId, film_name, director, and genre\n","with open(csv_file, 'w', newline='') as csvfile:\n","    writer = csv.writer(csvfile)\n","    writer.writerow(['imdbId', 'film_name', 'director', 'genre'])  # Header row\n","    for data in data_list:\n","        writer.writerow([data['imdbId'], data['film_name'], data['director'], data['genre']])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Specify the path to save the CSV in the writable /kaggle/working directory\n","csv_file = '/kaggle/working/imdb_data.csv'  # Change the directory to /kaggle/working\n","\n","# Save the processed data to a CSV file with only imdbId, film_name, director, and genre\n","with open(csv_file, 'w', newline='') as csvfile:\n","    writer = csv.writer(csvfile)\n","    writer.writerow(['imdbId', 'film_name', 'director', 'genre'])  # Header row\n","    for data in data_list:\n","        writer.writerow([data['imdbId'], data['film_name'], data['director'], data['genre']])\n"]},{"cell_type":"markdown","metadata":{},"source":["# handling data more effectivly"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import imdb\n","import csv\n","import pandas as pd\n","import concurrent.futures\n","import urllib.error\n","import time\n","from tqdm import tqdm  # For progress tracking\n","\n","# Load the movie IDs (Assuming 'data' is a DataFrame that contains imdbId)\n","imdbs = data['imdbId']\n","\n","# Set up the IMDb API\n","ia = imdb.IMDb()\n","\n","# Define the batch size for processing\n","batch_size = 100\n","\n","# Define the function to get movie data with retry logic\n","def get_movie_data(movie_id, retries=3):\n","    for _ in range(retries):\n","        try:\n","            movie = ia.get_movie(movie_id)\n","\n","            # Fetch the required data without explicitly updating 'directors' or 'genres'\n","            data = {\n","                'imdbId': movie_id,\n","                'film_name': movie.get('title', ''),\n","                'director': ', '.join([person['name'] for person in movie.get('directors', [])]) if movie.get('directors') else '',\n","                'genre': ', '.join(movie.get('genres', [])) if movie.get('genres') else ''\n","            }\n","            return data\n","        except (imdb.IMDbDataAccessError, urllib.error.HTTPError) as e:\n","            time.sleep(1)  # Wait for 1 second before retrying\n","    # If retries are exhausted, return empty data\n","    return {'imdbId': movie_id, 'film_name': '', 'director': '', 'genre': ''}\n","\n","# Define the function to process a batch of movie IDs\n","def process_batch(movie_ids):\n","    data_list = []\n","    for movie_id in movie_ids:\n","        data_list.append(get_movie_data(movie_id))\n","    return data_list\n","\n","# Create a list to store the processed data\n","data_list = []\n","\n","# Create a ThreadPoolExecutor to parallelize the API calls\n","with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n","    # Split the movie IDs into batches\n","    batches = [imdbs[i:i + batch_size] for i in range(0, len(imdbs), batch_size)]\n","    \n","    # Process each batch in parallel and use tqdm for progress tracking\n","    futures = [executor.submit(process_batch, batch) for batch in batches]\n","    \n","    # Collect the results with progress tracking\n","    for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc=\"Processing batches\"):\n","        data_list.extend(future.result())\n","\n","# Specify the path to save the CSV\n","csv_file = '/kaggle/input/imdbdata/imdb_data.csv'\n","\n","# Save the processed data to a CSV file with only imdbId, film_name, director, and genre\n","with open(csv_file, 'w', newline='') as csvfile:\n","    writer = csv.writer(csvfile)\n","    writer.writerow(['imdbId', 'film_name', 'director', 'genre'])  # Header row\n","    for data in data_list:\n","        writer.writerow([data['imdbId'], data['film_name'], data['director'], data['genre']])\n"]},{"cell_type":"markdown","metadata":{},"source":["# updated needed features to current file"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import imdb\n","import pandas as pd\n","import concurrent.futures\n","\n","# Extract the list of IMDb IDs\n","imdbs = data['imdbId']\n","\n","# Set up the IMDb API\n","ia = imdb.IMDb()\n","\n","# Define the batch size for processing\n","batch_size = 100\n","\n","# Define the function to get movie data\n","def get_movie_data(movie_id):\n","    try:\n","        movie = ia.get_movie(movie_id)\n","        ia.update(movie, 'reviews')\n","        ia.update(movie, 'cast')\n","        ia.update(movie, 'directors')\n","        ia.update(movie, 'writers')\n","\n","        # Return the new data, using `.get()` to safely handle missing fields\n","        data = {\n","            'imdbId': movie_id,\n","            'director': ', '.join([person.get('name', '') for person in movie.get('directors', [])]) if movie.get('directors') else '',\n","            'writer': ', '.join([person.get('name', '') for person in movie.get('writers', [])]) if movie.get('writers') else '',\n","            'genre': ', '.join(movie.get('genres', [])) if movie.get('genres') else ''  # join genre list\n","        }\n","        return data\n","    except imdb.IMDbDataAccessError as e:\n","        return {'imdbId': movie_id, 'director': '', 'writer': '', 'genre': ''}\n","    \n","# Define the function to process a batch of movie IDs\n","def process_batch(movie_ids):\n","    data_list = []\n","    for movie_id in movie_ids:\n","        data_list.append(get_movie_data(movie_id))\n","    return data_list\n","\n","# Create a list to store the processed data\n","data_list = []\n","\n","# Create a ThreadPoolExecutor to parallelize the API calls\n","with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n","    # Split the movie IDs into batches\n","    batches = [imdbs[i:i + batch_size] for i in range(0, len(imdbs), batch_size)]\n","    \n","    # Process each batch in parallel\n","    futures = [executor.submit(process_batch, batch) for batch in batches]\n","    \n","    # Collect the results\n","    for future in concurrent.futures.as_completed(futures):\n","        data_list.extend(future.result())\n","\n","# Convert the collected data into a DataFrame\n","new_data_df = pd.DataFrame(data_list)\n","\n","# Merge the new data with the existing dataset\n","updated_data = pd.merge(data, new_data_df, on='imdbId', how='left')\n","\n","# Save the updated data back to the CSV file\n","updated_data.to_csv(csv_file, index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data_list"]},{"cell_type":"markdown","metadata":{},"source":["# download the csv file"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","# Create a Pandas DataFrame from the data_list\n","df = pd.DataFrame(data_list)\n","\n","df.to_csv('imdb_data.csv', index=False)\n","from IPython.display import FileLink\n","\n","# This will create a download link for the file\n","FileLink('imdb_data.csv')"]},{"cell_type":"markdown","metadata":{},"source":["# imdb reccomendation"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T12:59:00.945543Z","iopub.status.busy":"2024-09-17T12:59:00.944294Z","iopub.status.idle":"2024-09-17T12:59:15.442087Z","shell.execute_reply":"2024-09-17T12:59:15.440438Z","shell.execute_reply.started":"2024-09-17T12:59:00.945454Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter a movie name or IMDb ID:  heat\n"]},{"name":"stdout","output_type":"stream","text":["Top 3 recommended movies for heat:\n","No recommendations\n"]}],"source":["import imdb\n","import pandas as pd\n","import concurrent.futures\n","\n","# Set up the IMDb API\n","ia = imdb.IMDb()\n","\n","# Define the function to get movie data based on movie title or IMDb ID\n","def get_movie_id(user_input):\n","    # Try to interpret input as an IMDb ID (numeric)\n","    try:\n","        movie_id = int(user_input)\n","        movie = ia.get_movie(movie_id)\n","    except ValueError:\n","        # If not a number, assume it's a movie title and search by title\n","        search_results = ia.search_movie(user_input)\n","        if search_results:\n","            # Take the first search result as the most likely match\n","            movie = search_results[0]\n","        else:\n","            return None  # Return None if no results found\n","    \n","    return movie.movieID  # Return the movie ID\n","\n","# Define the function to get movie recommendations\n","def get_recommendations(movie_id):\n","    try:\n","        movie = ia.get_movie(movie_id)\n","        ia.update(movie, 'recommendations')  # Fetch recommendations\n","\n","        # Get the recommended movies (up to 3 recommendations)\n","        recommended_movies = movie.get('recommendations', [])[:3]\n","        recommended_titles = ', '.join([rec.get('title', '') for rec in recommended_movies]) if recommended_movies else 'No recommendations'\n","\n","        # Return the top 3 recommendations\n","        return {\n","            'imdbId': movie_id,\n","            'recommended_movies': recommended_titles  # Add the top 3 recommendations\n","        }\n","    except imdb.IMDbDataAccessError:\n","        return {'imdbId': movie_id, 'recommended_movies': 'No recommendations'}\n","\n","# User input function to accept either movie title or IMDb ID\n","def get_user_recommendations():\n","    user_input = input(\"Enter a movie name or IMDb ID: \")\n","\n","    # Normalize user input (case insensitive, remove extra spaces)\n","    user_input_normalized = user_input.strip().lower()\n","\n","    # Get the IMDb movie ID\n","    movie_id = get_movie_id(user_input_normalized)\n","    if movie_id:\n","        # Fetch recommendations if the movie ID is valid\n","        recommendations = get_recommendations(movie_id)\n","        print(f\"Top 3 recommended movies for {user_input}:\")\n","        print(recommendations['recommended_movies'])\n","    else:\n","        print(\"Sorry, no movie found with that name or IMDb ID.\")\n","\n","# Run the recommendation system for user input\n","get_user_recommendations()\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T13:02:22.028975Z","iopub.status.busy":"2024-09-17T13:02:22.028558Z","iopub.status.idle":"2024-09-17T13:02:30.523943Z","shell.execute_reply":"2024-09-17T13:02:30.521753Z","shell.execute_reply.started":"2024-09-17T13:02:22.028934Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter a movie name or IMDb ID:  heat\n"]},{"name":"stdout","output_type":"stream","text":["Top 3 recommended movies for heat:\n"]},{"ename":"TypeError","evalue":"string indices must be integers","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_user_recommendations\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[2], line 56\u001b[0m, in \u001b[0;36mget_user_recommendations\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m     recommendations \u001b[38;5;241m=\u001b[39m get_recommendations(movie_id)\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop 3 recommended movies for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mrecommendations\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecommended_movies\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSorry, no movie found with that name or IMDb ID.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mTypeError\u001b[0m: string indices must be integers"]}],"source":["get_user_recommendations()"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T13:07:11.952939Z","iopub.status.busy":"2024-09-17T13:07:11.951141Z","iopub.status.idle":"2024-09-17T13:07:20.356174Z","shell.execute_reply":"2024-09-17T13:07:20.354276Z","shell.execute_reply.started":"2024-09-17T13:07:11.952851Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter a movie name or IMDb ID:  inception\n"]},{"name":"stdout","output_type":"stream","text":["No recommendations available for 'Inception'. The IMDb API may not have this data.\n"]}],"source":["import imdb\n","\n","# Set up the IMDb API\n","ia = imdb.IMDb()\n","\n","# Function to get movie recommendations\n","def get_recommendations(movie_input):\n","    try:\n","        # Check if input is numeric (IMDb ID) or a movie name\n","        if movie_input.isdigit():  # IMDb ID\n","            movie = ia.get_movie(movie_input)\n","        else:  # Movie name\n","            search_results = ia.search_movie(movie_input)\n","            if not search_results:\n","                return f\"No movie found for '{movie_input}'\"\n","            movie = search_results[0]  # Take the first search result\n","\n","        # Get movie title\n","        movie_title = movie.get('title', movie_input)\n","\n","        # Try to update with recommendations\n","        ia.update(movie, 'recommendations')\n","        recommended_movies = movie.get('recommendations', [])\n","\n","        # If recommendations are missing, provide more feedback\n","        if not recommended_movies:\n","            return f\"No recommendations available for '{movie_title}'. The IMDb API may not have this data.\"\n","\n","        # Format the top 3 recommendations\n","        recommended_titles = ', '.join([rec.get('title', '') for rec in recommended_movies[:3]])\n","        return f\"Top 3 recommended movies for {movie_title}:\\n{recommended_titles}\"\n","\n","    except imdb.IMDbDataAccessError:\n","        return f\"Error accessing IMDb data for '{movie_input}'\"\n","    except Exception as e:\n","        return f\"An error occurred: {str(e)}\"\n","\n","# Main interaction loop\n","def main():\n","    movie_input = input(\"Enter a movie name or IMDb ID: \").strip()\n","\n","    # Get and display recommendations\n","    result = get_recommendations(movie_input)\n","    print(result)\n","\n","# Run the main function\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T13:19:33.641795Z","iopub.status.busy":"2024-09-17T13:19:33.641280Z","iopub.status.idle":"2024-09-17T13:19:41.552624Z","shell.execute_reply":"2024-09-17T13:19:41.549534Z","shell.execute_reply.started":"2024-09-17T13:19:33.641746Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter a movie name or IMDb ID:  me before you\n"]},{"name":"stdout","output_type":"stream","text":["Movie found: Me Before You\n","Recommendations: []\n","Genres: []\n","Keywords: []\n","No recommendations or similar movies available for 'Me Before You'.\n"]}],"source":["import imdb\n","\n","# Set up the IMDb API\n","ia = imdb.IMDb()\n","\n","# Function to get movie recommendations or similar movies by keywords/genres\n","def get_similar_movies(movie_input):\n","    try:\n","        # Check if input is numeric (IMDb ID) or a movie name\n","        if movie_input.isdigit():  # IMDb ID\n","            movie = ia.get_movie(movie_input)\n","        else:  # Movie name\n","            search_results = ia.search_movie(movie_input)\n","            if not search_results:\n","                return f\"No movie found for '{movie_input}'\"\n","            movie = search_results[0]  # Take the first search result\n","\n","        # Get movie title\n","        movie_title = movie.get('title', movie_input)\n","        print(f\"Movie found: {movie_title}\")\n","\n","        # First, try to get recommendations\n","        ia.update(movie, 'recommendations')\n","        recommended_movies = movie.get('recommendations', [])\n","        print(f\"Recommendations: {recommended_movies}\")\n","\n","        # If recommendations are available, use them\n","        if recommended_movies:\n","            recommended_titles = ', '.join([rec.get('title', '') for rec in recommended_movies[:3]])\n","            return f\"Top 3 recommended movies for '{movie_title}':\\n{recommended_titles}\"\n","\n","        # Access genres and keywords directly from the movie object\n","        genres = movie.get('genres', [])\n","        keywords = movie.get('keywords', [])\n","        print(f\"Genres: {genres}\")\n","        print(f\"Keywords: {keywords}\")\n","\n","        # Search for similar movies based on genre or keywords\n","        if genres:\n","            similar_titles = ', '.join([f\"Similar movie {i+1}\" for i in range(3)])\n","            return f\"No recommendations available for '{movie_title}'. Similar movies by genre:\\n{similar_titles}\"\n","\n","        if keywords:\n","            similar_titles = ', '.join([f\"Similar movie {i+1}\" for i in range(3)])\n","            return f\"No recommendations available for '{movie_title}'. Similar movies by keyword:\\n{similar_titles}\"\n","\n","        # If no similar movies found, return a fallback message\n","        return f\"No recommendations or similar movies available for '{movie_title}'.\"\n","\n","    except imdb.IMDbDataAccessError:\n","        return f\"Error accessing IMDb data for '{movie_input}'\"\n","    except Exception as e:\n","        return f\"An error occurred: {str(e)}\"\n","\n","# Main interaction loop\n","def main():\n","    movie_input = input(\"Enter a movie name or IMDb ID: \").strip()\n","\n","    # Get and display similar movies or recommendations\n","    result = get_similar_movies(movie_input)\n","    print(result)\n","\n","# Run the main function\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T13:21:02.429038Z","iopub.status.busy":"2024-09-17T13:21:02.428464Z","iopub.status.idle":"2024-09-17T13:21:11.967435Z","shell.execute_reply":"2024-09-17T13:21:11.965643Z","shell.execute_reply.started":"2024-09-17T13:21:02.428984Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter a movie name or IMDb ID:  interstellar\n"]},{"name":"stdout","output_type":"stream","text":["Movie found: Interstellar\n","Recommendations: []\n","Genres: ['Adventure', 'Drama', 'Sci-Fi']\n","Keywords: []\n","No recommendations available for 'Interstellar'. Similar movies by genre:\n","Similar movie 1, Similar movie 2, Similar movie 3\n"]}],"source":["import imdb\n","\n","# Set up the IMDb API\n","ia = imdb.IMDb()\n","\n","# Function to get movie recommendations or similar movies by keywords/genres\n","def get_similar_movies(movie_input):\n","    try:\n","        # Check if input is numeric (IMDb ID) or a movie name\n","        if movie_input.isdigit():  # IMDb ID\n","            movie = ia.get_movie(movie_input)\n","        else:  # Movie name\n","            search_results = ia.search_movie(movie_input)\n","            if not search_results:\n","                return f\"No movie found for '{movie_input}'\"\n","            movie = search_results[0]  # Take the first search result\n","\n","        # Get movie title\n","        movie_title = movie.get('title', movie_input)\n","        print(f\"Movie found: {movie_title}\")\n","\n","        # First, try to get recommendations\n","        ia.update(movie, 'recommendations')\n","        recommended_movies = movie.get('recommendations', [])\n","        print(f\"Recommendations: {recommended_movies}\")\n","\n","        # If recommendations are available, use them\n","        if recommended_movies:\n","            recommended_titles = ', '.join([rec.get('title', '') for rec in recommended_movies[:3]])\n","            return f\"Top 3 recommended movies for '{movie_title}':\\n{recommended_titles}\"\n","\n","        # Update movie with more information\n","        ia.update(movie)\n","        genres = movie.get('genres', [])\n","        keywords = movie.get('keywords', [])\n","        print(f\"Genres: {genres}\")\n","        print(f\"Keywords: {keywords}\")\n","\n","        # Search for similar movies based on genre or keywords\n","        if genres:\n","            similar_titles = ', '.join([f\"Similar movie {i+1}\" for i in range(3)])\n","            return f\"No recommendations available for '{movie_title}'. Similar movies by genre:\\n{similar_titles}\"\n","\n","        if keywords:\n","            similar_titles = ', '.join([f\"Similar movie {i+1}\" for i in range(3)])\n","            return f\"No recommendations available for '{movie_title}'. Similar movies by keyword:\\n{similar_titles}\"\n","\n","        # If no similar movies found, return a fallback message\n","        return f\"No recommendations or similar movies available for '{movie_title}'.\"\n","\n","    except imdb.IMDbDataAccessError:\n","        return f\"Error accessing IMDb data for '{movie_input}'\"\n","    except Exception as e:\n","        return f\"An error occurred: {str(e)}\"\n","\n","# Main interaction loop\n","def main():\n","    movie_input = input(\"Enter a movie name or IMDb ID: \").strip()\n","\n","    # Get and display similar movies or recommendations\n","    result = get_similar_movies(movie_input)\n","    print(result)\n","\n","# Run the main function\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T13:21:39.648580Z","iopub.status.busy":"2024-09-17T13:21:39.647888Z","iopub.status.idle":"2024-09-17T13:21:48.121031Z","shell.execute_reply":"2024-09-17T13:21:48.119689Z","shell.execute_reply.started":"2024-09-17T13:21:39.648510Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter a movie name or IMDb ID:  heat\n"]},{"name":"stdout","output_type":"stream","text":["Movie found: Heat\n","Recommendations: []\n","Genres: ['Action', 'Crime', 'Drama']\n","Keywords: []\n"]},{"name":"stderr","output_type":"stream","text":["2024-09-17 13:21:48,107 ERROR [imdbpy.parser.http.domparser] /opt/conda/lib/python3.10/site-packages/imdb/parser/http/utils.py:438: DOMHTMLSearchMovieAdvancedParser: caught exception postprocessing data\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/site-packages/imdb/parser/http/utils.py\", line 436, in parse\n","    data = self.postprocess_data(data)\n","  File \"/opt/conda/lib/python3.10/site-packages/imdb/parser/http/searchMovieAdvancedParser.py\", line 207, in postprocess_data\n","    data['data'] = []\n","TypeError: 'mappingproxy' object does not support item assignment\n"]},{"name":"stdout","output_type":"stream","text":["An error occurred: 'data'\n"]}],"source":["import imdb\n","\n","# Set up the IMDb API\n","ia = imdb.IMDb()\n","\n","# Function to get movie recommendations or similar movies by keywords/genres\n","def get_similar_movies(movie_input):\n","    try:\n","        # Check if input is numeric (IMDb ID) or a movie name\n","        if movie_input.isdigit():  # IMDb ID\n","            movie = ia.get_movie(movie_input)\n","        else:  # Movie name\n","            search_results = ia.search_movie(movie_input)\n","            if not search_results:\n","                return f\"No movie found for '{movie_input}'\"\n","            movie = search_results[0]  # Take the first search result\n","\n","        # Get movie title\n","        movie_title = movie.get('title', movie_input)\n","        print(f\"Movie found: {movie_title}\")\n","\n","        # First, try to get recommendations\n","        ia.update(movie, 'recommendations')\n","        recommended_movies = movie.get('recommendations', [])\n","        print(f\"Recommendations: {recommended_movies}\")\n","\n","        # If recommendations are available, use them\n","        if recommended_movies:\n","            recommended_titles = ', '.join([rec.get('title', '') for rec in recommended_movies[:3]])\n","            return f\"Top 3 recommended movies for '{movie_title}':\\n{recommended_titles}\"\n","\n","        # Update movie with more information\n","        ia.update(movie)\n","        genres = movie.get('genres', [])\n","        keywords = movie.get('keywords', [])\n","        print(f\"Genres: {genres}\")\n","        print(f\"Keywords: {keywords}\")\n","\n","        # Search for similar movies based on genre\n","        if genres:\n","            similar_movies = []\n","            for genre in genres:\n","                genre_movies = ia.get_top50_movies_by_genres(genre)\n","                similar_movies.extend(genre_movies)\n","            similar_movies = list({movie.movieID: movie for movie in similar_movies}.values())  # Remove duplicates\n","            similar_titles = ', '.join([sim_movie.get('title', '') for sim_movie in similar_movies[:3]])\n","            return f\"No recommendations available for '{movie_title}'. Similar movies by genre:\\n{similar_titles}\"\n","\n","        # If no similar movies found, return a fallback message\n","        return f\"No recommendations or similar movies available for '{movie_title}'.\"\n","\n","    except imdb.IMDbDataAccessError:\n","        return f\"Error accessing IMDb data for '{movie_input}'\"\n","    except Exception as e:\n","        return f\"An error occurred: {str(e)}\"\n","\n","# Main interaction loop\n","def main():\n","    movie_input = input(\"Enter a movie name or IMDb ID: \").strip()\n","\n","    # Get and display similar movies or recommendations\n","    result = get_similar_movies(movie_input)\n","    print(result)\n","\n","# Run the main function\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T13:22:30.952055Z","iopub.status.busy":"2024-09-17T13:22:30.951551Z","iopub.status.idle":"2024-09-17T13:22:38.788170Z","shell.execute_reply":"2024-09-17T13:22:38.785554Z","shell.execute_reply.started":"2024-09-17T13:22:30.952009Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter a movie name or IMDb ID:  heat\n"]},{"name":"stdout","output_type":"stream","text":["Movie found: Heat\n","Recommendations: []\n","Genres: ['Action', 'Crime', 'Drama']\n","An error occurred: IMDbBase.search_movie_advanced() got an unexpected keyword argument 'genre'\n"]}],"source":["import imdb\n","\n","# Set up the IMDb API\n","ia = imdb.IMDb()\n","\n","# Function to get movie recommendations or similar movies by keywords/genres\n","def get_similar_movies(movie_input):\n","    try:\n","        # Check if input is numeric (IMDb ID) or a movie name\n","        if movie_input.isdigit():  # IMDb ID\n","            movie = ia.get_movie(movie_input)\n","        else:  # Movie name\n","            search_results = ia.search_movie(movie_input)\n","            if not search_results:\n","                return f\"No movie found for '{movie_input}'\"\n","            movie = search_results[0]  # Take the first search result\n","\n","        # Get movie title\n","        movie_title = movie.get('title', movie_input)\n","        print(f\"Movie found: {movie_title}\")\n","\n","        # First, try to get recommendations\n","        ia.update(movie, 'recommendations')\n","        recommended_movies = movie.get('recommendations', [])\n","        print(f\"Recommendations: {recommended_movies}\")\n","\n","        # If recommendations are available, use them\n","        if recommended_movies:\n","            recommended_titles = ', '.join([rec.get('title', '') for rec in recommended_movies[:3]])\n","            return f\"Top 3 recommended movies for '{movie_title}':\\n{recommended_titles}\"\n","\n","        # Update movie with more information\n","        ia.update(movie)\n","        genres = movie.get('genres', [])\n","        print(f\"Genres: {genres}\")\n","\n","        # Search for similar movies based on genre\n","        if genres:\n","            similar_movies = []\n","            for genre in genres:\n","                search_results = ia.search_movie_advanced(genre=genre)\n","                similar_movies.extend(search_results[:3])  # Get top 3 movies for each genre\n","            similar_movies = list({movie.movieID: movie for movie in similar_movies}.values())  # Remove duplicates\n","            similar_titles = ', '.join([sim_movie.get('title', '') for sim_movie in similar_movies[:3]])\n","            return f\"No recommendations available for '{movie_title}'. Similar movies by genre:\\n{similar_titles}\"\n","\n","        # If no similar movies found, return a fallback message\n","        return f\"No recommendations or similar movies available for '{movie_title}'.\"\n","\n","    except imdb.IMDbDataAccessError:\n","        return f\"Error accessing IMDb data for '{movie_input}'\"\n","    except Exception as e:\n","        return f\"An error occurred: {str(e)}\"\n","\n","# Main interaction loop\n","def main():\n","    movie_input = input(\"Enter a movie name or IMDb ID: \").strip()\n","\n","    # Get and display similar movies or recommendations\n","    result = get_similar_movies(movie_input)\n","    print(result)\n","\n","# Run the main function\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T13:23:37.505501Z","iopub.status.busy":"2024-09-17T13:23:37.504871Z","iopub.status.idle":"2024-09-17T13:23:50.137664Z","shell.execute_reply":"2024-09-17T13:23:50.136093Z","shell.execute_reply.started":"2024-09-17T13:23:37.505443Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter a movie name or IMDb ID:  heat\n"]},{"name":"stdout","output_type":"stream","text":["Movie found: Heat\n","Recommendations: []\n","Genres: ['Action', 'Crime', 'Drama']\n","No recommendations available for 'Heat'. Similar movies by genre:\n","Action, Last Action Hero, Back in Action\n"]}],"source":["import imdb\n","\n","# Set up the IMDb API\n","ia = imdb.IMDb()\n","\n","# Function to get movie recommendations or similar movies by keywords/genres\n","def get_similar_movies(movie_input):\n","    try:\n","        # Check if input is numeric (IMDb ID) or a movie name\n","        if movie_input.isdigit():  # IMDb ID\n","            movie = ia.get_movie(movie_input)\n","        else:  # Movie name\n","            search_results = ia.search_movie(movie_input)\n","            if not search_results:\n","                return f\"No movie found for '{movie_input}'\"\n","            movie = search_results[0]  # Take the first search result\n","\n","        # Get movie title\n","        movie_title = movie.get('title', movie_input)\n","        print(f\"Movie found: {movie_title}\")\n","\n","        # First, try to get recommendations\n","        ia.update(movie, 'recommendations')\n","        recommended_movies = movie.get('recommendations', [])\n","        print(f\"Recommendations: {recommended_movies}\")\n","\n","        # If recommendations are available, use them\n","        if recommended_movies:\n","            recommended_titles = ', '.join([rec.get('title', '') for rec in recommended_movies[:3]])\n","            return f\"Top 3 recommended movies for '{movie_title}':\\n{recommended_titles}\"\n","\n","        # Update movie with more information\n","        ia.update(movie)\n","        genres = movie.get('genres', [])\n","        print(f\"Genres: {genres}\")\n","\n","        # Search for similar movies based on genre\n","        if genres:\n","            similar_movies = []\n","            for genre in genres:\n","                search_results = ia.search_movie(genre)\n","                similar_movies.extend(search_results[:3])  # Get top 3 movies for each genre\n","            similar_movies = list({movie.movieID: movie for movie in similar_movies}.values())  # Remove duplicates\n","            similar_titles = ', '.join([sim_movie.get('title', '') for sim_movie in similar_movies[:3]])\n","            return f\"No recommendations available for '{movie_title}'. Similar movies by genre:\\n{similar_titles}\"\n","\n","        # If no similar movies found, return a fallback message\n","        return f\"No recommendations or similar movies available for '{movie_title}'.\"\n","\n","    except imdb.IMDbDataAccessError:\n","        return f\"Error accessing IMDb data for '{movie_input}'\"\n","    except Exception as e:\n","        return f\"An error occurred: {str(e)}\"\n","\n","# Main interaction loop\n","def main():\n","    movie_input = input(\"Enter a movie name or IMDb ID: \").strip()\n","\n","    # Get and display similar movies or recommendations\n","    result = get_similar_movies(movie_input)\n","    print(result)\n","\n","# Run the main function\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T13:26:21.997055Z","iopub.status.busy":"2024-09-17T13:26:21.995565Z","iopub.status.idle":"2024-09-17T13:26:33.639661Z","shell.execute_reply":"2024-09-17T13:26:33.637705Z","shell.execute_reply.started":"2024-09-17T13:26:21.996969Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter a movie name or IMDb ID:  heat\n"]},{"name":"stdout","output_type":"stream","text":["Movie found: Heat\n","Recommendations: []\n","Genres: ['Action', 'Crime', 'Drama']\n","No recommendations available for 'Heat'. Similar movies by genre:\n","Gundam I: The Live-Action Movie, Gintama Live Action the Movie, Ryan: First Mission (Fardeen Khan, Kartik Aaryan)\n"]}],"source":["import imdb\n","\n","# Set up the IMDb API\n","ia = imdb.IMDb()\n","\n","# Function to get movie recommendations or similar movies by keywords/genres\n","def get_similar_movies(movie_input):\n","    try:\n","        # Check if input is numeric (IMDb ID) or a movie name\n","        if movie_input.isdigit():  # IMDb ID\n","            movie = ia.get_movie(movie_input)\n","        else:  # Movie name\n","            search_results = ia.search_movie(movie_input)\n","            if not search_results:\n","                return f\"No movie found for '{movie_input}'\"\n","            movie = search_results[0]  # Take the first search result\n","\n","        # Get movie title\n","        movie_title = movie.get('title', movie_input)\n","        print(f\"Movie found: {movie_title}\")\n","\n","        # First, try to get recommendations\n","        ia.update(movie, 'recommendations')\n","        recommended_movies = movie.get('recommendations', [])\n","        print(f\"Recommendations: {recommended_movies}\")\n","\n","        # If recommendations are available, use them\n","        if recommended_movies:\n","            recommended_titles = ', '.join([rec.get('title', '') for rec in recommended_movies[:3]])\n","            return f\"Top 3 recommended movies for '{movie_title}':\\n{recommended_titles}\"\n","\n","        # Update movie with more information\n","        ia.update(movie)\n","        genres = movie.get('genres', [])\n","        print(f\"Genres: {genres}\")\n","\n","        # Search for similar movies based on all genres\n","        similar_movies = []\n","        for genre in genres:\n","            search_results = ia.search_movie(f\"{genre} movie\")\n","            similar_movies.extend(search_results[:3])  # Get top 3 movies for each genre\n","        similar_movies = list({movie.movieID: movie for movie in similar_movies}.values())  # Remove duplicates\n","        similar_titles = ', '.join([sim_movie.get('title', '') for sim_movie in similar_movies[:3]])\n","\n","        return f\"No recommendations available for '{movie_title}'. Similar movies by genre:\\n{similar_titles}\"\n","\n","    except imdb.IMDbDataAccessError:\n","        return f\"Error accessing IMDb data for '{movie_input}'\"\n","    except Exception as e:\n","        return f\"An error occurred: {str(e)}\"\n","\n","# Main interaction loop\n","def main():\n","    movie_input = input(\"Enter a movie name or IMDb ID: \").strip()\n","\n","    # Get and display similar movies or recommendations\n","    result = get_similar_movies(movie_input)\n","    print(result)\n","\n","# Run the main function\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T13:13:06.200900Z","iopub.status.busy":"2024-09-17T13:13:06.200495Z","iopub.status.idle":"2024-09-17T13:13:11.792884Z","shell.execute_reply":"2024-09-17T13:13:11.791301Z","shell.execute_reply.started":"2024-09-17T13:13:06.200859Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter a movie name or IMDb ID:  interstellar\n"]},{"name":"stdout","output_type":"stream","text":["Movie found: Interstellar (2014)\n","Genres: []\n","Movie: Interstellar (2014) | Genres: \n"]}],"source":["import imdb\n","\n","# Set up the IMDb API\n","ia = imdb.IMDb()\n","\n","# Function to fetch basic movie details\n","def get_movie_info(movie_input):\n","    try:\n","        # Check if input is IMDb ID (numeric) or movie title (string)\n","        if movie_input.isdigit():\n","            movie = ia.get_movie(movie_input)\n","        else:\n","            search_results = ia.search_movie(movie_input)\n","            if not search_results:\n","                return f\"No movie found for '{movie_input}'\"\n","            movie = search_results[0]  # Take the first search result\n","        \n","        # Print basic information for debugging\n","        movie_title = movie.get('title', 'Unknown Title')\n","        movie_year = movie.get('year', 'Unknown Year')\n","        genres = movie.get('genres', [])\n","        print(f\"Movie found: {movie_title} ({movie_year})\")\n","        print(f\"Genres: {genres}\")\n","\n","        return f\"Movie: {movie_title} ({movie_year}) | Genres: {', '.join(genres)}\"\n","\n","    except imdb.IMDbDataAccessError:\n","        return f\"Error accessing IMDb data for '{movie_input}'\"\n","    except Exception as e:\n","        return f\"An error occurred: {str(e)}\"\n","\n","# Main interaction loop\n","def main():\n","    movie_input = input(\"Enter a movie name or IMDb ID: \").strip()\n","\n","    # Get and display movie info\n","    result = get_movie_info(movie_input)\n","    print(result)\n","\n","# Run the main function\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"markdown","metadata":{},"source":["# assosication"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","from mlxtend.frequent_patterns import fpgrowth, association_rules\n","\n","# Load the dataset in chunks\n","chunksize = 1000\n","chunks = pd.read_csv(r'/kaggle/input/rating/ratings.csv', chunksize=chunksize)\n","\n","# Concatenate all chunks into a single DataFrame\n","ratings = pd.concat(chunks, ignore_index=True)\n","\n","# Filter only ratings of 4.0 and above for \"liked\" movies\n","ratings_filtered = ratings[ratings['rating'] >= 4.0]\n","\n","# Create a user-item matrix\n","user_movie_matrix = ratings_filtered.pivot_table(index='userId', columns='movieId', aggfunc='size', fill_value=0)\n","\n","# Apply FP-Growth to find frequent item sets\n","frequent_itemsets = fpgrowth(user_movie_matrix, min_support=0.02, use_colnames=True)\n","\n","# Generate association rules\n","rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)\n","\n","# Sort the rules by lift\n","rules = rules.sort_values(by='lift', ascending=False)\n","\n","# Display the rules\n","print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])\n"]},{"cell_type":"markdown","metadata":{},"source":["# assosiation model "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","from mlxtend.frequent_patterns import fpgrowth, association_rules\n","\n","# Load the dataset in chunks\n","chunksize = 1000\n","chunks = pd.read_csv(r'/kaggle/input/rating/ratings.csv', chunksize=chunksize)\n","\n","# Concatenate all chunks into a single DataFrame\n","ratings = pd.concat(chunks, ignore_index=True)\n","\n","# Filter only ratings of 4.0 and above for \"liked\" movies\n","ratings_filtered = ratings[ratings['rating'] >= 4.0]\n","\n","# Create a user-item matrix, where 1 represents a \"liked\" movie (rating 4.0 or above)\n","user_movie_matrix = ratings_filtered.pivot_table(index='userId', columns='movieId', aggfunc='size', fill_value=0)\n","\n","# Apply FP-Growth to find frequent item sets\n","frequent_itemsets = fpgrowth(user_movie_matrix, min_support=0.02, use_colnames=True)\n","\n","# Generate association rules\n","rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)\n","\n","# Sort the rules by lift\n","rules = rules.sort_values(by='lift', ascending=False)\n","\n","# Load the movies dataset to map movie IDs to movie titles\n","movies = pd.read_csv(r'/kaggle/input/movielens/movies.csv')\n","\n","# Create a function to get movie recommendations\n","def get_movie_id(movie_title):\n","    \"\"\"\n","    Get the movieId for the given movie title from the movies dataset.\n","    \"\"\"\n","    movie_id = movies[movies['title'].str.contains(movie_title, case=False, na=False)]['movieId']\n","    if len(movie_id) > 0:\n","        return movie_id.values[0]\n","    else:\n","        return None\n","\n","def recommend_movies(movie_title, rules, movies, top_n=3):\n","    \"\"\"\n","    Recommend associated movies based on the input movie title.\n","    \"\"\"\n","    movie_id = get_movie_id(movie_title)\n","    if movie_id is None:\n","        return f\"Movie '{movie_title}' not found in the dataset.\"\n","\n","    # Find rules where the input movie is in the antecedents\n","    matching_rules = rules[rules['antecedents'].apply(lambda x: movie_id in x)]\n","\n","    if matching_rules.empty:\n","        return f\"No associated movies found for '{movie_title}'.\"\n","\n","    # Extract the consequents from the association rules\n","    movie_recommendations = []\n","    for _, row in matching_rules.iterrows():\n","        for consequent in row['consequents']:\n","            if consequent != movie_id:\n","                movie_recommendations.append((consequent, row['lift']))\n","\n","    # Remove duplicates and sort by lift value (descending)\n","    movie_recommendations = sorted(list(set(movie_recommendations)), key=lambda x: x[1], reverse=True)\n","\n","    # Get the top N movie recommendations\n","    recommended_movie_ids = [rec[0] for rec in movie_recommendations[:top_n]]\n","    recommended_movies = movies[movies['movieId'].isin(recommended_movie_ids)]['title'].values\n","\n","    return recommended_movies\n","\n","# Example usage:\n","movie_name = 'Interstellar'  # Change this to the movie title you want recommendations for\n","recommended_movies = recommend_movies(movie_name, rules, movies)\n","\n","if isinstance(recommended_movies, str):\n","    print(recommended_movies)  # If the function returns an error message\n","else:\n","    print(f\"Movies recommended based on '{movie_name}':\")\n","    for i, movie in enumerate(recommended_movies, 1):\n","        print(f\"{i}. {movie}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# assosiation model low resources"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","from mlxtend.frequent_patterns import fpgrowth, association_rules\n","from scipy.sparse import csr_matrix\n","\n","# Load the dataset in chunks to avoid memory overload\n","chunksize = 10**6  # Increase the chunksize to process more data at once but keep it manageable\n","chunks = pd.read_csv(r'/kaggle/input/rating/ratings.csv', chunksize=chunksize, usecols=['userId', 'movieId', 'rating'])\n","\n","# Initialize an empty list to store filtered data\n","filtered_chunks = []\n","\n","# Process each chunk individually\n","for chunk in chunks:\n","    # Filter ratings of 4.0 and above for \"liked\" movies\n","    filtered_chunk = chunk[chunk['rating'] >= 4.0]\n","    filtered_chunks.append(filtered_chunk)\n","\n","# Concatenate all filtered chunks into a single DataFrame\n","ratings_filtered = pd.concat(filtered_chunks, ignore_index=True)\n","\n","# Create a user-item matrix in sparse format to save memory\n","user_movie_matrix = ratings_filtered.pivot_table(index='userId', columns='movieId', aggfunc='size', fill_value=0)\n","user_movie_matrix_sparse = csr_matrix(user_movie_matrix.values)\n","\n","# Apply FP-Growth to find frequent item sets\n","frequent_itemsets = fpgrowth(pd.DataFrame(user_movie_matrix_sparse.todense(), columns=user_movie_matrix.columns), min_support=0.02, use_colnames=True)\n","\n","# Generate association rules from the frequent item sets\n","rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)\n","\n","# Sort the rules by lift to find the most interesting ones\n","rules = rules.sort_values(by='lift', ascending=False)\n","\n","# Load the movies dataset to map movie IDs to movie titles\n","movies = pd.read_csv(r'/kaggle/input/movielens/movies.csv')\n","\n","# Create a function to get movie recommendations\n","def get_movie_id(movie_title):\n","    \"\"\"\n","    Get the movieId for the given movie title from the movies dataset.\n","    \"\"\"\n","    movie_id = movies[movies['title'].str.contains(movie_title, case=False, na=False)]['movieId']\n","    if len(movie_id) > 0:\n","        return movie_id.values[0]\n","    else:\n","        return None\n","\n","def recommend_movies(movie_title, rules, movies, top_n=3):\n","    \"\"\"\n","    Recommend associated movies based on the input movie title.\n","    \"\"\"\n","    movie_id = get_movie_id(movie_title)\n","    if movie_id is None:\n","        return f\"Movie '{movie_title}' not found in the dataset.\"\n","\n","    # Find rules where the input movie is in the antecedents\n","    matching_rules = rules[rules['antecedents'].apply(lambda x: movie_id in x)]\n","\n","    if matching_rules.empty:\n","        return f\"No associated movies found for '{movie_title}'.\"\n","\n","    # Extract the consequents from the association rules\n","    movie_recommendations = []\n","    for _, row in matching_rules.iterrows():\n","        for consequent in row['consequents']:\n","            if consequent != movie_id:\n","                movie_recommendations.append((consequent, row['lift']))\n","\n","    # Remove duplicates and sort by lift value (descending)\n","    movie_recommendations = sorted(list(set(movie_recommendations)), key=lambda x: x[1], reverse=True)\n","\n","    # Get the top N movie recommendations\n","    recommended_movie_ids = [rec[0] for rec in movie_recommendations[:top_n]]\n","    recommended_movies = movies[movies['movieId'].isin(recommended_movie_ids)]['title'].values\n","\n","    return recommended_movies\n","\n","# Example usage:\n","movie_name = 'Interstellar'  # Change this to the movie title you want recommendations for\n","recommended_movies = recommend_movies(movie_name, rules, movies)\n","\n","if isinstance(recommended_movies, str):\n","    print(recommended_movies)  # If the function returns an error message\n","else:\n","    print(f\"Movies recommended based on '{movie_name}':\")\n","    for i, movie in enumerate(recommended_movies, 1):\n","        print(f\"{i}. {movie}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# final try "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","from mlxtend.frequent_patterns import fpgrowth, association_rules\n","from scipy.sparse import csr_matrix\n","import re\n","\n","# Function to clean movie titles by removing special characters and lowercasing\n","def clean_movie_title(title):\n","    # Remove anything in parentheses (like year)\n","    title = re.sub(r'\\(.*?\\)', '', title)\n","    # Remove extra spaces and lowercase the title\n","    title = re.sub(r'\\s+', ' ', title).strip().lower()\n","    return title\n","\n","# Load the dataset in chunks\n","chunksize = 10**6\n","chunks = pd.read_csv(r'/kaggle/input/rating/ratings.csv', chunksize=chunksize, usecols=['userId', 'movieId', 'rating'])\n","\n","# Initialize an empty list to store filtered data\n","filtered_chunks = []\n","\n","# Process each chunk individually\n","for chunk in chunks:\n","    # Filter ratings of 4.0 and above for \"liked\" movies\n","    filtered_chunk = chunk[chunk['rating'] >= 4.0]\n","    filtered_chunks.append(filtered_chunk)\n","\n","# Concatenate filtered chunks\n","ratings_filtered = pd.concat(filtered_chunks, ignore_index=True)\n","\n","# Create a user-item matrix in sparse format\n","user_movie_matrix = ratings_filtered.pivot_table(index='userId', columns='movieId', aggfunc='size', fill_value=0)\n","user_movie_matrix_sparse = csr_matrix(user_movie_matrix.values)\n","\n","# Apply FP-Growth to find frequent item sets\n","frequent_itemsets = fpgrowth(pd.DataFrame(user_movie_matrix_sparse.todense(), columns=user_movie_matrix.columns), min_support=0.05, use_colnames=True)\n","\n","# Generate association rules from frequent item sets\n","rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)\n","\n","# Sort rules by lift\n","rules = rules.sort_values(by='lift', ascending=False)\n","\n","# Load the movies dataset\n","movies = pd.read_csv(r'/kaggle/input/movielens/movies.csv')\n","\n","# Apply the clean_movie_title function to standardize movie titles\n","movies['clean_title'] = movies['title'].apply(clean_movie_title)\n","\n","# Create a function to get movie recommendations\n","def get_movie_id(movie_title):\n","    \"\"\"\n","    Get the movieId for the given movie title from the movies dataset.\n","    Clean the input movie title for consistency.\n","    \"\"\"\n","    cleaned_title = clean_movie_title(movie_title)\n","    movie_id = movies[movies['clean_title'] == cleaned_title]['movieId']\n","    \n","    if len(movie_id) > 0:\n","        return movie_id.values[0]\n","    else:\n","        return None\n","\n","def recommend_movies(movie_title, rules, movies, top_n=3):\n","    \"\"\"\n","    Recommend associated movies based on the input movie title.\n","    \"\"\"\n","    movie_id = get_movie_id(movie_title)\n","    if movie_id is None:\n","        return f\"Movie '{movie_title}' not found in the dataset.\"\n","\n","    # Find rules where the input movie is in the antecedents\n","    matching_rules = rules[rules['antecedents'].apply(lambda x: movie_id in x)]\n","\n","    if matching_rules.empty:\n","        return f\"No associated movies found for '{movie_title}'.\"\n","\n","    # Extract the consequents from the association rules\n","    movie_recommendations = []\n","    for _, row in matching_rules.iterrows():\n","        for consequent in row['consequents']:\n","            if consequent != movie_id:\n","                movie_recommendations.append((consequent, row['lift']))\n","\n","    # Remove duplicates and sort by lift value\n","    movie_recommendations = sorted(list(set(movie_recommendations)), key=lambda x: x[1], reverse=True)\n","\n","    # Get top N movie recommendations\n","    recommended_movie_ids = [rec[0] for rec in movie_recommendations[:top_n]]\n","    recommended_movies = movies[movies['movieId'].isin(recommended_movie_ids)]['title'].values\n","\n","    return recommended_movies\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Example usage:\n","movie_name = 'Heat (1995)'  # You can try different variations like 'interstellar'\n","recommended_movies = recommend_movies(movie_name, rules, movies)\n","\n","if isinstance(recommended_movies, str):\n","    print(recommended_movies)  # Error message\n","else:\n","    print(f\"Movies recommended based on '{movie_name}':\")\n","    for i, movie in enumerate(recommended_movies, 1):\n","        print(f\"{i}. {movie}\")"]},{"cell_type":"markdown","metadata":{},"source":["# cosine matrix improved"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import re\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# Load the movie dataset\n","data = pd.read_csv(r'D:\\abdo\\AI\\projects\\recommender\\needed features\\imdb_data.csv')\n","\n","# Convert data to a DataFrame\n","df = pd.DataFrame(data)\n","\n","# Replace NaN values in relevant columns with an empty string\n","df['overview'] = df['overview'].fillna('')\n","df['reviews'] = df['reviews'].fillna('')\n","df['cast'] = df['cast'].fillna('')\n","df['director'] = df['director'].fillna('')\n","df['genre'] = df['genre'].fillna('')\n","\n","# Combine 'title', 'overview', 'cast', 'director', 'genre', and 'reviews' for similarity comparison\n","df['combined_features'] = df['title'] + ' ' + df['overview'] + ' ' + df['cast'] + ' ' + df['director'] + ' ' + df['genre'] + ' ' + df['reviews']\n","\n","# Text Vectorization using TF-IDF (including bi-grams for better context)\n","tfidf = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))\n","tfidf_matrix = tfidf.fit_transform(df['combined_features'].fillna(''))\n","\n","# Calculate cosine similarity between all movies\n","cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n","\n","# Helper function to extract movie title\n","def extract_title(title):\n","    if pd.isna(title):\n","        return ''\n","    title = title.lower()\n","    title = re.sub(r'\\s*\\(\\d{4}\\)$', '', title)  # Remove year information\n","    return title\n","\n","# Define the function to recommend movies\n","def recommend_movies(movie_title, cosine_sim=cosine_sim, df=df):\n","    movie_title_clean = extract_title(movie_title)\n","    \n","    # Check if the movie title exists in the dataset\n","    if movie_title_clean in df['title'].apply(extract_title).values:\n","        # Get the index of the movie that matches the title\n","        idx = df.index[df['title'].apply(extract_title) == movie_title_clean][0]\n","        \n","        # Get the pairwise similarity scores of all movies with that movie\n","        sim_scores = list(enumerate(cosine_sim[idx]))\n","        \n","        # Sort the movies based on similarity scores\n","        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n","        \n","        # Get the top 3 most similar movies (excluding the input movie itself)\n","        recommended_movies = []\n","        for score in sim_scores[1:]:\n","            movie_data = df.iloc[score[0]]\n","            recommended_movies.append({\n","                'title': movie_data['title'],\n","                'film_rate': movie_data['film_rate'],\n","                'imdbId': movie_data['imdbId'],\n","                'cover_url': movie_data['cover_url'],\n","                'director': movie_data['director'],\n","                'genre': movie_data['genre'],\n","                'cast': movie_data['cast'],\n","                'overview': movie_data['overview'],\n","                'reviews': movie_data['reviews']\n","            })\n","            if len(recommended_movies) == 3:  # Limit to top 3 movies\n","                break\n","        \n","        # Return the top 3 most similar movies with all requested details\n","        return recommended_movies\n","    else:\n","        return []  # Return an empty list if the movie is not found\n","\n","# Example usage: Recommend movies based on the title \"Heat\"\n","test = 'heat'\n","recommended_movies = recommend_movies(test)\n","print(f\"Movies recommended based on '{test}':\")\n","for movie in recommended_movies:\n","    print(f\"Title: {movie['title']}, Rating: {movie['film_rate']}, IMDb ID: {movie['imdbId']}\")\n","    print(f\"Director: {movie['director']}, Genre: {movie['genre']}\")\n","    print(f\"Cast: {movie['cast']}\")\n","    print(f\"Overview: {movie['overview']}\")\n","    print(f\"Reviews: {movie['reviews']}\")\n","    print(f\"Cover URL: {movie['cover_url']}\")\n","    print(\"-\" * 80)\n"]},{"cell_type":"markdown","metadata":{},"source":["# LSTM"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T00:08:33.209532Z","iopub.status.busy":"2024-09-17T00:08:33.209207Z","iopub.status.idle":"2024-09-17T00:08:47.878961Z","shell.execute_reply":"2024-09-17T00:08:47.877612Z","shell.execute_reply.started":"2024-09-17T00:08:33.209491Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.16.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.11.0)\n","Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.3.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (70.0.0)\n","Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.62.2)\n","Requirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.16.2)\n","Requirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.3)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.37.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n","Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n","Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install tensorflow"]},{"cell_type":"markdown","metadata":{},"source":["# lstm 256 patch size adam w "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T19:52:02.499403Z","iopub.status.busy":"2024-09-16T19:52:02.498521Z","iopub.status.idle":"2024-09-16T19:52:38.813252Z","shell.execute_reply":"2024-09-16T19:52:38.812295Z","shell.execute_reply.started":"2024-09-16T19:52:02.499352Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import re\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# Load the movie dataset\n","data = pd.read_csv(r'/kaggle/input/movies-updated/movies_with_tags_rating.csv')\n","\n","# Preprocessing\n","df = pd.DataFrame(data)\n","df['overview'] = df['overview'].fillna('')\n","df['cast'] = df['cast'].fillna('')\n","df['director'] = df['director'].fillna('(no data about the director is found)')\n","df['genre'] = df['genre'].fillna('')\n","df['tag'] = df['tag'].fillna('')\n","df['reviews'] = df['reviews'].fillna('')\n","\n","# Combine features into a single column for text processing\n","df['combined_features'] = df['overview'] + ' ' + df['cast'] + ' ' + df['director'] + ' ' + df['genre'] + ' ' + df['tag'] + ' ' + df['reviews']\n","\n","# Tokenization and padding\n","max_words = 10000\n","max_sequence_len = 300\n","\n","tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(df['combined_features'])\n","sequences = tokenizer.texts_to_sequences(df['combined_features'])\n","padded_sequences = pad_sequences(sequences, maxlen=max_sequence_len, padding='post', truncating='post')\n","\n","# Define LSTM model\n","embedding_dim = 100\n","\n","model = Sequential()\n","model.add(Embedding(max_words, embedding_dim, input_length=max_sequence_len))\n","model.add(LSTM(128, return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(LSTM(64))\n","model.add(Dense(32, activation='relu'))\n","model.add(Dense(16, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(loss='binary_crossentropy', optimizer='AdamW', metrics=['accuracy'])\n","model.summary()\n","\n","# Split data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df['rating'], test_size=0.2, random_state=42)\n","\n","# Train the LSTM model\n","model.fit(X_train, y_train, epochs=5, batch_size=256, validation_data=(X_test, y_test))\n","\n","# Generate embeddings from the trained LSTM model\n","embedding_layer = Sequential()\n","embedding_layer.add(model.layers[0])\n","embedding_layer.add(model.layers[1])\n","embedding_layer.compile(loss='binary_crossentropy', optimizer='AdamW')\n","\n","# Generate embeddings for all movies\n","movie_embeddings = embedding_layer.predict(padded_sequences)\n","\n","# Flatten the LSTM output by averaging over timesteps\n","movie_embeddings_2d = np.mean(movie_embeddings, axis=1)\n","\n","# Calculate cosine similarity based on 2D embeddings\n","cosine_sim_lstm = cosine_similarity(movie_embeddings_2d, movie_embeddings_2d)\n","\n","# Function to clean movie titles (remove special characters and lowercase)\n","def extract_title(title):\n","    # Check if the title is NaN or not a string, return an empty string in that case\n","    if isinstance(title, str):\n","        title_cleaned = title.lower()\n","        title_cleaned = re.sub(r'\\W+', ' ', title_cleaned)\n","        return title_cleaned.strip()\n","    else:\n","        return np.nan\n","\n","# Function to recommend movies based on LSTM embeddings\n","def recommend_movies_lstm(movie_title, cosine_sim=cosine_sim_lstm, df=df):\n","    movie_title_clean = extract_title(movie_title)\n","    \n","    # Check if the movie title exists in the dataset\n","    if movie_title_clean in df['title'].apply(extract_title).values:\n","        # Get the index of the movie that matches the title\n","        idx = df.index[df['title'].apply(extract_title) == movie_title_clean][0]\n","        \n","        # Get the pairwise similarity scores of all movies with that movie\n","        sim_scores = list(enumerate(cosine_sim[idx]))\n","        \n","        # Sort the movies based on similarity scores\n","        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n","        \n","        # Get the top 3 most similar movies (excluding the input movie itself)\n","        recommended_movies = []\n","        for score in sim_scores[1:]:\n","            movie_data = df.iloc[score[0]]\n","            recommended_movies.append({\n","                'title': movie_data['title'],\n","                'film_rate': movie_data['film_rate'],\n","                'imdbId': movie_data['imdbId'],\n","                'cover_url': movie_data['cover_url'],\n","                'director': movie_data['director'],\n","                'genre': movie_data['genre'],\n","                'cast': movie_data['cast'],\n","                'overview': movie_data['overview'],\n","                'reviews': movie_data['reviews'],\n","                'tag': movie_data['tag'],\n","                'rating': movie_data['rating']\n","            })\n","            if len(recommended_movies) == 3:  # Limit to top 3 movies\n","                break\n","        \n","        # Return the top 3 most similar movies with all requested details\n","        return recommended_movies\n","    else:\n","        return []  # Return an empty list if the movie is not found\n","# Example usage with LSTM model\n","test_movie = 'heat'\n","recommended_movies_lstm = recommend_movies_lstm(test_movie)\n","\n","if not recommended_movies_lstm:\n","    print(f\"'{test_movie}' is not listed in our database.\")\n","else:\n","    print(f\"Movies recommended based on '{test_movie}':\")\n","    for movie in recommended_movies_lstm:\n","        print(f\"Title: {movie['title']}, Rating: {movie['film_rate']}, User Rating: {movie['rating']}, Tags: {movie['tag']}\")\n","        print(f\"Director: {movie['director']}\")\n","        print(f\"Genre: {movie['genre']}\")\n","        print(\"-\" * 80)\n"]},{"cell_type":"markdown","metadata":{},"source":["# lstm 256 batch adam"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import re\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# Load the movie dataset\n","data = pd.read_csv(r'/kaggle/input/movies-updated/movies_with_tags_rating.csv')\n","\n","# Preprocessing\n","df = pd.DataFrame(data)\n","df['overview'] = df['overview'].fillna('')\n","df['cast'] = df['cast'].fillna('')\n","df['director'] = df['director'].fillna('(no data about the director is found)')\n","df['genre'] = df['genre'].fillna('')\n","df['tag'] = df['tag'].fillna('')\n","df['reviews'] = df['reviews'].fillna('')\n","\n","# Combine features into a single column for text processing\n","df['combined_features'] = df['overview'] + ' ' + df['cast'] + ' ' + df['director'] + ' ' + df['genre'] + ' ' + df['tag'] + ' ' + df['reviews']\n","\n","# Tokenization and padding\n","max_words = 10000\n","max_sequence_len = 300\n","\n","tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(df['combined_features'])\n","sequences = tokenizer.texts_to_sequences(df['combined_features'])\n","padded_sequences = pad_sequences(sequences, maxlen=max_sequence_len, padding='post', truncating='post')\n","\n","# Define LSTM model\n","embedding_dim = 100\n","\n","model = Sequential()\n","model.add(Embedding(max_words, embedding_dim, input_length=max_sequence_len))\n","model.add(LSTM(128, return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(LSTM(64))\n","model.add(Dense(32, activation='relu'))\n","model.add(Dense(16, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.summary()\n","\n","# Split data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df['rating'], test_size=0.2, random_state=42)\n","\n","# Train the LSTM model\n","model.fit(X_train, y_train, epochs=5, batch_size=256, validation_data=(X_test, y_test))\n","\n","# Generate embeddings from the trained LSTM model\n","embedding_layer = Sequential()\n","embedding_layer.add(model.layers[0])\n","embedding_layer.add(model.layers[1])\n","embedding_layer.compile(loss='binary_crossentropy', optimizer='Adam')\n","\n","# Generate embeddings for all movies\n","movie_embeddings = embedding_layer.predict(padded_sequences)\n","\n","# Flatten the LSTM output by averaging over timesteps\n","movie_embeddings_2d = np.mean(movie_embeddings, axis=1)\n","\n","# Calculate cosine similarity based on 2D embeddings\n","cosine_sim_lstm = cosine_similarity(movie_embeddings_2d, movie_embeddings_2d)\n","\n","# Function to clean movie titles (remove special characters and lowercase)\n","def extract_title(title):\n","    # Check if the title is NaN or not a string, return an empty string in that case\n","    if isinstance(title, str):\n","        title_cleaned = title.lower()\n","        title_cleaned = re.sub(r'\\W+', ' ', title_cleaned)\n","        return title_cleaned.strip()\n","    else:\n","        return np.nan\n","\n","# Function to recommend movies based on LSTM embeddings\n","def recommend_movies_lstm(movie_title, cosine_sim=cosine_sim_lstm, df=df):\n","    movie_title_clean = extract_title(movie_title)\n","    \n","    # Check if the movie title exists in the dataset\n","    if movie_title_clean in df['title'].apply(extract_title).values:\n","        # Get the index of the movie that matches the title\n","        idx = df.index[df['title'].apply(extract_title) == movie_title_clean][0]\n","        \n","        # Get the pairwise similarity scores of all movies with that movie\n","        sim_scores = list(enumerate(cosine_sim[idx]))\n","        \n","        # Sort the movies based on similarity scores\n","        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n","        \n","        # Get the top 3 most similar movies (excluding the input movie itself)\n","        recommended_movies = []\n","        for score in sim_scores[1:]:\n","            movie_data = df.iloc[score[0]]\n","            recommended_movies.append({\n","                'title': movie_data['title'],\n","                'film_rate': movie_data['film_rate'],\n","                'imdbId': movie_data['imdbId'],\n","                'cover_url': movie_data['cover_url'],\n","                'director': movie_data['director'],\n","                'genre': movie_data['genre'],\n","                'cast': movie_data['cast'],\n","                'overview': movie_data['overview'],\n","                'reviews': movie_data['reviews'],\n","                'tag': movie_data['tag'],\n","                'rating': movie_data['rating']\n","            })\n","            if len(recommended_movies) == 3:  # Limit to top 3 movies\n","                break\n","        \n","        # Return the top 3 most similar movies with all requested details\n","        return recommended_movies\n","    else:\n","        return []  # Return an empty list if the movie is not found\n","# Example usage with LSTM model\n","test_movie = 'heat'\n","recommended_movies_lstm = recommend_movies_lstm(test_movie)\n","\n","if not recommended_movies_lstm:\n","    print(f\"'{test_movie}' is not listed in our database.\")\n","else:\n","    print(f\"Movies recommended based on '{test_movie}':\")\n","    for movie in recommended_movies_lstm:\n","        print(f\"Title: {movie['title']}, Rating: {movie['film_rate']}, User Rating: {movie['rating']}, Tags: {movie['tag']}\")\n","        print(f\"Director: {movie['director']}\")\n","        print(f\"Genre: {movie['genre']}\")\n","        print(\"-\" * 80)\n"]},{"cell_type":"markdown","metadata":{},"source":["# another try "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T20:00:17.304805Z","iopub.status.busy":"2024-09-16T20:00:17.304374Z","iopub.status.idle":"2024-09-16T20:00:54.157644Z","shell.execute_reply":"2024-09-16T20:00:54.156641Z","shell.execute_reply.started":"2024-09-16T20:00:17.304769Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import re\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# Load the movie dataset\n","data = pd.read_csv(r'/kaggle/input/movies-updated/movies_with_tags_rating.csv')\n","\n","# Preprocessing\n","df = pd.DataFrame(data)\n","df['overview'] = df['overview'].fillna('')\n","df['cast'] = df['cast'].fillna('')\n","df['director'] = df['director'].fillna('(no data about the director is found)')\n","df['genre'] = df['genre'].fillna('')\n","df['tag'] = df['tag'].fillna('')\n","df['reviews'] = df['reviews'].fillna('')\n","\n","# Feature Weighting\n","df['combined_features'] = (df['overview'] * 1 + ' ' +\n","                           df['cast'] * 3 + ' ' + \n","                           df['director'] * 4 + ' ' + \n","                           df['genre'] * 5 + ' ' + \n","                           df['tag'] * 2 + ' ' + \n","                           df['reviews'] * 1)\n","# Tokenization and padding\n","max_words = 10000\n","max_sequence_len = 300\n","\n","tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(df['combined_features'])\n","sequences = tokenizer.texts_to_sequences(df['combined_features'])\n","padded_sequences = pad_sequences(sequences, maxlen=max_sequence_len, padding='post', truncating='post')\n","\n","# Define LSTM model\n","embedding_dim = 100\n","\n","model = Sequential()\n","model.add(Embedding(max_words, embedding_dim, input_length=max_sequence_len))\n","model.add(LSTM(128, return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(LSTM(64))\n","model.add(Dense(32, activation='relu'))\n","model.add(Dense(16, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.summary()\n","\n","# Split data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df['rating'], test_size=0.2, random_state=42)\n","\n","# Train the LSTM model\n","model.fit(X_train, y_train, epochs=5, batch_size=256, validation_data=(X_test, y_test))\n","\n","# Generate embeddings from the trained LSTM model\n","embedding_layer = Sequential()\n","embedding_layer.add(model.layers[0])\n","embedding_layer.add(model.layers[1])\n","embedding_layer.compile(loss='binary_crossentropy', optimizer='Adam')\n","\n","# Generate embeddings for all movies\n","movie_embeddings = embedding_layer.predict(padded_sequences)\n","\n","# Flatten the LSTM output by averaging over timesteps\n","movie_embeddings_2d = np.mean(movie_embeddings, axis=1)\n","\n","# Calculate cosine similarity based on 2D embeddings\n","cosine_sim_lstm = cosine_similarity(movie_embeddings_2d, movie_embeddings_2d)\n","\n","# Function to clean movie titles (remove special characters and lowercase)\n","def extract_title(title):\n","    if isinstance(title, str):\n","        title_cleaned = title.lower()\n","        title_cleaned = re.sub(r'\\W+', ' ', title_cleaned)\n","        return title_cleaned.strip()\n","    else:\n","        return np.nan\n","\n","# Function to recommend movies based on LSTM embeddings\n","def recommend_movies_lstm(movie_title, cosine_sim=cosine_sim_lstm, df=df):\n","    movie_title_clean = extract_title(movie_title)\n","    \n","    # Check if the movie title exists in the dataset\n","    if movie_title_clean in df['title'].apply(extract_title).values:\n","        # Get the index of the movie that matches the title\n","        idx = df.index[df['title'].apply(extract_title) == movie_title_clean][0]\n","        \n","        # Get the pairwise similarity scores of all movies with that movie\n","        sim_scores = list(enumerate(cosine_sim[idx]))\n","        \n","        # Sort the movies based on similarity scores\n","        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n","        \n","        # Get the top 3 most similar movies (excluding the input movie itself)\n","        recommended_movies = []\n","        for score in sim_scores[1:]:\n","            movie_data = df.iloc[score[0]]\n","            recommended_movies.append({\n","                'title': movie_data['title'],\n","                'film_rate': movie_data['film_rate'],\n","                'imdbId': movie_data['imdbId'],\n","                'cover_url': movie_data['cover_url'],\n","                'director': movie_data['director'],\n","                'genre': movie_data['genre'],\n","                'cast': movie_data['cast'],\n","                'overview': movie_data['overview'],\n","                'reviews': movie_data['reviews'],\n","                'tag': movie_data['tag'],\n","                'rating': movie_data['rating']\n","            })\n","            if len(recommended_movies) == 3:  # Limit to top 3 movies\n","                break\n","        \n","        # Return the top 3 most similar movies with all requested details\n","        return recommended_movies\n","    else:\n","        return []  # Return an empty list if the movie is not found\n","\n","# Example usage with LSTM model\n","test_movie = 'heat'\n","recommended_movies_lstm = recommend_movies_lstm(test_movie)\n","\n","if not recommended_movies_lstm:\n","    print(f\"'{test_movie}' is not listed in our database.\")\n","else:\n","    print(f\"Movies recommended based on '{test_movie}':\")\n","    for movie in recommended_movies_lstm:\n","        print(f\"Title: {movie['title']}, Rating: {movie['film_rate']}, User Rating: {movie['rating']}, Tags: {movie['tag']}\")\n","        print(f\"Director: {movie['director']}\")\n","        print(f\"Genre: {movie['genre']}\")\n","        print(\"-\" * 80)\n"]},{"cell_type":"markdown","metadata":{},"source":["# lstm and attention  no weights"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T00:44:23.620919Z","iopub.status.busy":"2024-09-17T00:44:23.619970Z","iopub.status.idle":"2024-09-17T00:45:41.294415Z","shell.execute_reply":"2024-09-17T00:45:41.293432Z","shell.execute_reply.started":"2024-09-17T00:44:23.620874Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_35\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"functional_35\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding_10        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> │ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │ embedding_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dropout_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ attention_10        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ lstm_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19200</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">614,432</span> │ flatten_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ dense_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ dense_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding_10        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │  \u001b[38;5;34m1,000,000\u001b[0m │ input_layer_10[\u001b[38;5;34m0\u001b[0m… │\n","│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_20 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m117,248\u001b[0m │ embedding_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dropout_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ lstm_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n","│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_21 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m49,408\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ attention_10        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ lstm_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n","│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ lstm_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19200\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ attention_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_29 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │    \u001b[38;5;34m614,432\u001b[0m │ flatten_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_30 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m528\u001b[0m │ dense_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_31 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m17\u001b[0m │ dense_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,781,633</span> (6.80 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,781,633\u001b[0m (6.80 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,781,633</span> (6.80 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,781,633\u001b[0m (6.80 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 0.9299 - loss: 0.1423\n","Epoch 2/5\n","\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n","Epoch 3/5\n","\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n","Epoch 4/5\n","\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n","Epoch 5/5\n","\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n","\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n","Movies recommended based on 'heat':\n","Title: Hitchcock, Rating: 6.8, User Rating: 3.4, Tags: \n","Director: Sacha Gervasi\n","Genre: Biography, Drama, Romance\n","--------------------------------------------------------------------------------\n","Title: Zapped!, Rating: 4.9, User Rating: 2.45, Tags: \n","Director: Robert J. Rosenthal\n","Genre: Comedy, Fantasy, Sci-Fi\n","--------------------------------------------------------------------------------\n","Title: Kick-Ass 2, Rating: 6.5, User Rating: 3.25, Tags: \n","Director: Jeff Wadlow\n","Genre: Action, Comedy, Crime, Drama, Thriller\n","--------------------------------------------------------------------------------\n"]}],"source":["import pandas as pd\n","import re\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Input, Attention, Flatten\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# Load the movie dataset\n","data = pd.read_csv(r'/kaggle/input/movies-updated/movies_with_tags_rating.csv')\n","\n","# Preprocessing\n","df = pd.DataFrame(data)\n","df['overview'] = df['overview'].fillna('')\n","df['cast'] = df['cast'].fillna('')\n","df['director'] = df['director'].fillna('(no data about the director is found)')\n","df['genre'] = df['genre'].fillna('')\n","df['tag'] = df['tag'].fillna('')\n","df['reviews'] = df['reviews'].fillna('')\n","\n","# Feature Weighting\n","df['combined_features'] = (df['overview'] * 6 + ' ' +\n","                           df['cast'] * 1 + ' ' + \n","                           df['director'] * 4 + ' ' + \n","                           df['genre'] * 5 + ' ' + \n","                           df['tag'] * 1 + ' ' + \n","                           df['reviews'] * 1)\n","\n","\n","# Tokenization and padding\n","max_words = 10000\n","max_sequence_len = 300\n","\n","tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(df['combined_features'])\n","sequences = tokenizer.texts_to_sequences(df['combined_features'])\n","padded_sequences = pad_sequences(sequences, maxlen=max_sequence_len, padding='post', truncating='post')\n","\n","# Define LSTM model with Attention mechanism\n","embedding_dim = 100\n","\n","input_layer = Input(shape=(max_sequence_len,))\n","embedding_layer = Embedding(max_words, embedding_dim, input_length=max_sequence_len)(input_layer)\n","lstm_layer_1 = LSTM(128, return_sequences=True)(embedding_layer)\n","dropout_layer_1 = Dropout(0.2)(lstm_layer_1)\n","lstm_layer_2 = LSTM(64, return_sequences=True)(dropout_layer_1)\n","\n","# Attention mechanism\n","attention_layer = Attention()([lstm_layer_2, lstm_layer_2])\n","attention_output = Flatten()(attention_layer)  # Flatten the attention output\n","\n","dense_layer_1 = Dense(32, activation='relu')(attention_output)\n","dense_layer_2 = Dense(16, activation='relu')(dense_layer_1)\n","output_layer = Dense(1, activation='sigmoid')(dense_layer_2)\n","\n","model_with_attention = Model(inputs=input_layer, outputs=output_layer)\n","\n","model_with_attention.compile(loss='catigorical_cross_entropy', optimizer='adam', metrics=['accuracy'])\n","model_with_attention.summary()\n","\n","# Train the LSTM model with Attention mechanism\n","model_with_attention.fit(padded_sequences, np.ones(len(padded_sequences)), epochs=5, batch_size=256)\n","\n","# Generate embeddings from the trained LSTM model with Attention mechanism\n","embedding_model_with_attention = Model(inputs=model_with_attention.input,\n","                                       outputs=model_with_attention.layers[3].output)\n","movie_embeddings_with_attention = embedding_model_with_attention.predict(padded_sequences)\n","\n","# Flatten the LSTM output by averaging over timesteps\n","movie_embeddings_2d_with_attention = np.mean(movie_embeddings_with_attention, axis=1)\n","\n","# Calculate cosine similarity based on 2D embeddings with Attention mechanism\n","cosine_sim_lstm_with_attention = cosine_similarity(movie_embeddings_2d_with_attention, movie_embeddings_2d_with_attention)\n","\n","# Function to clean movie titles (remove special characters and lowercase)\n","def extract_title(title):\n","    if isinstance(title, str):\n","        title_cleaned = title.lower()\n","        title_cleaned = re.sub(r'\\W+', ' ', title_cleaned)\n","        return title_cleaned.strip()\n","    else:\n","        return np.nan\n","\n","# Function to recommend movies based on LSTM embeddings with Attention mechanism\n","def recommend_movies_lstm_with_attention(movie_title, cosine_sim=cosine_sim_lstm_with_attention, df=df):\n","    movie_title_clean = extract_title(movie_title)\n","    \n","    # Check if the movie title exists in the dataset\n","    if movie_title_clean in df['title'].apply(extract_title).values:\n","        # Get the index of the movie that matches the title\n","        idx = df.index[df['title'].apply(extract_title) == movie_title_clean][0]\n","        \n","        # Get the pairwise similarity scores of all movies with that movie\n","        sim_scores = list(enumerate(cosine_sim[idx]))\n","        \n","        # Sort the movies based on similarity scores\n","        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n","        \n","        # Get the top 3 most similar movies (excluding the input movie itself)\n","        recommended_movies = []\n","        for score in sim_scores[1:]:\n","            movie_data = df.iloc[score[0]]\n","            recommended_movies.append({\n","                'title': movie_data['title'],\n","                'film_rate': movie_data['film_rate'],\n","                'imdbId': movie_data['imdbId'],\n","                'cover_url': movie_data['cover_url'],\n","                'director': movie_data['director'],\n","                'genre': movie_data['genre'],\n","                'cast': movie_data['cast'],\n","                'overview': movie_data['overview'],\n","                'reviews': movie_data['reviews'],\n","                'tag': movie_data['tag'],\n","                'rating': movie_data['rating']\n","            })\n","            if len(recommended_movies) == 3:  # Limit to top 3 movies\n","                break\n","        \n","        # Return the top 3 most similar movies with all requested details\n","        return recommended_movies\n","    else:\n","        return []  # Return an empty list if the movie is not found\n","\n","# Example usage with LSTM model with Attention mechanism\n","test_movie = 'heat'\n","recommended_movies_lstm_with_attention = recommend_movies_lstm_with_attention(test_movie)\n","\n","if not recommended_movies_lstm_with_attention:\n","    print(f\"'{test_movie}' is not listed in our database.\")\n","else:\n","    print(f\"Movies recommended based on '{test_movie}':\")\n","    for movie in recommended_movies_lstm_with_attention:\n","        print(f\"Title: {movie['title']}, Rating: {movie['film_rate']}, User Rating: {movie['rating']}, Tags: {movie['tag']}\")\n","        print(f\"Director: {movie['director']}\")\n","        print(f\"Genre: {movie['genre']}\")\n","        print(\"-\" * 80)\n"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T00:46:02.669205Z","iopub.status.busy":"2024-09-17T00:46:02.668318Z","iopub.status.idle":"2024-09-17T00:46:02.765563Z","shell.execute_reply":"2024-09-17T00:46:02.764474Z","shell.execute_reply.started":"2024-09-17T00:46:02.669162Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Movies recommended based on 'interstellar':\n","Title: Spanglish, Rating: 6.4, User Rating: 3.2, Tags: \n","Director: James L. Brooks\n","Genre: Comedy, Drama, Romance\n","--------------------------------------------------------------------------------\n","Title: The Whistleblower, Rating: 7.1, User Rating: 3.55, Tags: \n","Director: Larysa Kondracki\n","Genre: Biography, Crime, Drama\n","--------------------------------------------------------------------------------\n","Title: Half Baked, Rating: 6.6, User Rating: 3.3, Tags: \n","Director: Tamra Davis\n","Genre: Comedy, Crime\n","--------------------------------------------------------------------------------\n"]}],"source":["test_movie = 'interstellar'\n","recommended_movies_lstm_with_attention = recommend_movies_lstm_with_attention(test_movie)\n","\n","if not recommended_movies_lstm_with_attention:\n","    print(f\"'{test_movie}' is not listed in our database.\")\n","else:\n","    print(f\"Movies recommended based on '{test_movie}':\")\n","    for movie in recommended_movies_lstm_with_attention:\n","        print(f\"Title: {movie['title']}, Rating: {movie['film_rate']}, User Rating: {movie['rating']}, Tags: {movie['tag']}\")\n","        print(f\"Director: {movie['director']}\")\n","        print(f\"Genre: {movie['genre']}\")\n","        print(\"-\" * 80)"]},{"cell_type":"markdown","metadata":{},"source":["# eclidian distance"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T01:16:07.354051Z","iopub.status.busy":"2024-09-17T01:16:07.353612Z","iopub.status.idle":"2024-09-17T01:37:38.798234Z","shell.execute_reply":"2024-09-17T01:37:38.797287Z","shell.execute_reply.started":"2024-09-17T01:16:07.354012Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_43\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"functional_43\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_12      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding_12        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> │ input_layer_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │ embedding_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dropout_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ attention_12        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ lstm_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ flatten_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19200</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">614,432</span> │ flatten_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ dense_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ dense_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_12      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding_12        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │  \u001b[38;5;34m1,000,000\u001b[0m │ input_layer_12[\u001b[38;5;34m0\u001b[0m… │\n","│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_24 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m117,248\u001b[0m │ embedding_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dropout_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ lstm_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n","│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_25 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m49,408\u001b[0m │ dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ attention_12        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ lstm_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n","│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ lstm_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ flatten_9 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19200\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ attention_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_35 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │    \u001b[38;5;34m614,432\u001b[0m │ flatten_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_36 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m528\u001b[0m │ dense_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_37 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m17\u001b[0m │ dense_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,781,633</span> (6.80 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,781,633\u001b[0m (6.80 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,781,633</span> (6.80 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,781,633\u001b[0m (6.80 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 0.9194 - loss: 0.1263\n","Epoch 2/5\n","\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n","Epoch 3/5\n","\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n","Epoch 4/5\n","\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n","Epoch 5/5\n","\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n","\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n","Movies recommended based on 'heat':\n","Title: Brothers, Rating: 7.1, User Rating: 3.55, Tags: \n","Director: Susanne Bier\n","Genre: Drama, War\n","--------------------------------------------------------------------------------\n","Title: Brothers, Rating: 7.1, User Rating: 3.55, Tags: \n","Director: Jim Sheridan\n","Genre: Drama, Thriller, War\n","--------------------------------------------------------------------------------\n","Title: Hitchcock, Rating: 6.8, User Rating: 3.4, Tags: \n","Director: Sacha Gervasi\n","Genre: Biography, Drama, Romance\n","--------------------------------------------------------------------------------\n","Movies recommended based on 'interstellar':\n","Title: The Lady Vanishes, Rating: 7.7, User Rating: 3.85, Tags: \n","Director: Alfred Hitchcock\n","Genre: Mystery, Thriller\n","--------------------------------------------------------------------------------\n","Title: Aguirre, the Wrath of God, Rating: 7.8, User Rating: 3.9, Tags: \n","Director: Werner Herzog\n","Genre: Action, Adventure, Biography, Drama, History\n","--------------------------------------------------------------------------------\n","Title: Crimson Peak, Rating: 6.5, User Rating: 3.25, Tags: \n","Director: Guillermo del Toro\n","Genre: Drama, Horror, Mystery, Romance, Thriller\n","--------------------------------------------------------------------------------\n"]}],"source":["import pandas as pd\n","import re\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Input, Attention, Flatten\n","from scipy.spatial.distance import euclidean\n","\n","# Load the movie dataset\n","data = pd.read_csv(r'/kaggle/input/movies-updated/movies_with_tags_rating.csv')\n","\n","# Preprocessing\n","df = pd.DataFrame(data)\n","df['overview'] = df['overview'].fillna('')\n","df['cast'] = df['cast'].fillna('')\n","df['director'] = df['director'].fillna('(no data about the director is found)')\n","df['genre'] = df['genre'].fillna('')\n","df['tag'] = df['tag'].fillna('')\n","df['reviews'] = df['reviews'].fillna('')\n","\n","# Feature Weighting\n","df['combined_features'] = (df['overview'] * 7 + ' ' +\n","                           df['cast'] * 1 + ' ' + \n","                           df['director'] * 4 + ' ' + \n","                           df['genre'] * 4 + ' ' + \n","                           df['tag'] * 1 + ' ' + \n","                           df['reviews'] * 1)\n","\n","\n","# Tokenization and padding\n","max_words = 10000\n","max_sequence_len = 300\n","\n","tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(df['combined_features'])\n","sequences = tokenizer.texts_to_sequences(df['combined_features'])\n","padded_sequences = pad_sequences(sequences, maxlen=max_sequence_len, padding='post', truncating='post')\n","\n","# Define LSTM model with Attention mechanism\n","embedding_dim = 100\n","\n","input_layer = Input(shape=(max_sequence_len,))\n","embedding_layer = Embedding(max_words, embedding_dim, input_length=max_sequence_len)(input_layer)\n","lstm_layer_1 = LSTM(128, return_sequences=True)(embedding_layer)\n","dropout_layer_1 = Dropout(0.2)(lstm_layer_1)\n","lstm_layer_2 = LSTM(64, return_sequences=True)(dropout_layer_1)\n","\n","# Attention mechanism\n","attention_layer = Attention()([lstm_layer_2, lstm_layer_2])\n","attention_output = Flatten()(attention_layer)  # Flatten the attention output\n","\n","dense_layer_1 = Dense(32, activation='relu')(attention_output)\n","dense_layer_2 = Dense(16, activation='relu')(dense_layer_1)\n","output_layer = Dense(1, activation='sigmoid')(dense_layer_2)\n","\n","model_with_attention = Model(inputs=input_layer, outputs=output_layer)\n","\n","model_with_attention.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model_with_attention.summary()\n","\n","# Train the LSTM model with Attention mechanism\n","model_with_attention.fit(padded_sequences, np.ones(len(padded_sequences)), epochs=5, batch_size=256)\n","\n","# Generate embeddings from the trained LSTM model with Attention mechanism\n","embedding_model_with_attention = Model(inputs=model_with_attention.input,\n","                                       outputs=model_with_attention.layers[3].output)\n","movie_embeddings_with_attention = embedding_model_with_attention.predict(padded_sequences)\n","\n","# Flatten the LSTM output by averaging over timesteps\n","movie_embeddings_2d_with_attention = np.mean(movie_embeddings_with_attention, axis=1)\n","\n","# Calculate Euclidean distance based on 2D embeddings with Attention mechanism\n","def calculate_euclidean_similarity(embeddings):\n","    num_movies = embeddings.shape[0]\n","    euclidean_sim = np.zeros((num_movies, num_movies))\n","    for i in range(num_movies):\n","        for j in range(num_movies):\n","            euclidean_sim[i, j] = euclidean(embeddings[i], embeddings[j])\n","    return euclidean_sim\n","\n","euclidean_sim_lstm_with_attention = calculate_euclidean_similarity(movie_embeddings_2d_with_attention)\n","\n","# Function to clean movie titles (remove special characters and lowercase)\n","def extract_title(title):\n","    if isinstance(title, str):\n","        title_cleaned = title.lower()\n","        title_cleaned = re.sub(r'\\W+', ' ', title_cleaned)\n","        return title_cleaned.strip()\n","    else:\n","        return np.nan\n","\n","# Function to recommend movies based on LSTM embeddings with Attention mechanism using Euclidean distance\n","def recommend_movies_lstm_with_euclidean(movie_title, euclidean_sim=euclidean_sim_lstm_with_attention, df=df):\n","    movie_title_clean = extract_title(movie_title)\n","    \n","    # Check if the movie title exists in the dataset\n","    if movie_title_clean in df['title'].apply(extract_title).values:\n","        # Get the index of the movie that matches the title\n","        idx = df.index[df['title'].apply(extract_title) == movie_title_clean][0]\n","        \n","        # Get the pairwise similarity scores of all movies with that movie\n","        sim_scores = list(enumerate(euclidean_sim[idx]))\n","        \n","        # Sort the movies based on similarity scores (ascending order for Euclidean distance)\n","        sim_scores = sorted(sim_scores, key=lambda x: x[1])\n","        \n","        # Get the top 3 most similar movies (excluding the input movie itself)\n","        recommended_movies = []\n","        for score in sim_scores[1:]:\n","            movie_data = df.iloc[score[0]]\n","            recommended_movies.append({\n","                'title': movie_data['title'],\n","                'film_rate': movie_data['film_rate'],\n","                'imdbId': movie_data['imdbId'],\n","                'cover_url': movie_data['cover_url'],\n","                'director': movie_data['director'],\n","                'genre': movie_data['genre'],\n","                'cast': movie_data['cast'],\n","                'overview': movie_data['overview'],\n","                'reviews': movie_data['reviews'],\n","                'tag': movie_data['tag'],\n","                'rating': movie_data['rating']\n","            })\n","            if len(recommended_movies) == 3:  # Limit to top 3 movies\n","                break\n","        \n","        # Return the top 3 most similar movies with all requested details\n","        return recommended_movies\n","    else:\n","        return []  # Return an empty list if the movie is not found\n","\n","# Example usage with LSTM model with Attention mechanism using Euclidean distance\n","test_movie_heat = 'heat'\n","recommended_movies_lstm_with_euclidean_heat = recommend_movies_lstm_with_euclidean(test_movie_heat)\n","\n","if not recommended_movies_lstm_with_euclidean_heat:\n","    print(f\"'{test_movie_heat}' is not listed in our database.\")\n","else:\n","    print(f\"Movies recommended based on '{test_movie_heat}':\")\n","    for movie in recommended_movies_lstm_with_euclidean_heat:\n","        print(f\"Title: {movie['title']}, Rating: {movie['film_rate']}, User Rating: {movie['rating']}, Tags: {movie['tag']}\")\n","        print(f\"Director: {movie['director']}\")\n","        print(f\"Genre: {movie['genre']}\")\n","        print(\"-\" * 80)\n","\n","test_movie_interstellar = 'interstellar'\n","recommended_movies_lstm_with_euclidean_interstellar = recommend_movies_lstm_with_euclidean(test_movie_interstellar)\n","\n","if not recommended_movies_lstm_with_euclidean_interstellar:\n","    print(f\"'{test_movie_interstellar}' is not listed in our database.\")\n","else:\n","    print(f\"Movies recommended based on '{test_movie_interstellar}':\")\n","    for movie in recommended_movies_lstm_with_euclidean_interstellar:\n","        print(f\"Title: {movie['title']}, Rating: {movie['film_rate']}, User Rating: {movie['rating']}, Tags: {movie['tag']}\")\n","        print(f\"Director: {movie['director']}\")\n","        print(f\"Genre: {movie['genre']}\")\n","        print(\"-\" * 80)\n"]},{"cell_type":"markdown","metadata":{},"source":["# PCA"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T01:38:07.557508Z","iopub.status.busy":"2024-09-17T01:38:07.557125Z","iopub.status.idle":"2024-09-17T01:59:23.592670Z","shell.execute_reply":"2024-09-17T01:59:23.591524Z","shell.execute_reply.started":"2024-09-17T01:38:07.557471Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_47\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"functional_47\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_13      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding_13        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> │ input_layer_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │ embedding_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dropout_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ attention_13        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ lstm_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ flatten_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19200</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">614,432</span> │ flatten_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ dense_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ dense_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_13      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding_13        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │  \u001b[38;5;34m1,000,000\u001b[0m │ input_layer_13[\u001b[38;5;34m0\u001b[0m… │\n","│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_26 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m117,248\u001b[0m │ embedding_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dropout_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ lstm_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n","│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_27 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m49,408\u001b[0m │ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ attention_13        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ lstm_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n","│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ lstm_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ flatten_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19200\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ attention_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n","│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_38 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │    \u001b[38;5;34m614,432\u001b[0m │ flatten_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_39 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m528\u001b[0m │ dense_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_40 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m17\u001b[0m │ dense_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,781,633</span> (6.80 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,781,633\u001b[0m (6.80 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,781,633</span> (6.80 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,781,633\u001b[0m (6.80 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.8270 - loss: 0.1749\n","Epoch 2/5\n","\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n","Epoch 3/5\n","\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n","Epoch 4/5\n","\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n","Epoch 5/5\n","\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n","\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n","Movies recommended based on 'heat':\n","Title: Jane Eyre, Rating: 7.5, User Rating: 3.75, Tags: \n","Director: Franco Zeffirelli\n","Genre: Drama, Romance\n","--------------------------------------------------------------------------------\n","Title: Jane Eyre, Rating: 7.5, User Rating: 3.75, Tags: \n","Director: Robert Stevenson\n","Genre: Drama, Romance\n","--------------------------------------------------------------------------------\n","Title: Jane Eyre, Rating: 7.5, User Rating: 3.75, Tags: \n","Director: Delbert Mann\n","Genre: Drama\n","--------------------------------------------------------------------------------\n","Movies recommended based on 'interstellar':\n","Title: Weirdsville, Rating: 6.2, User Rating: 3.1, Tags: \n","Director: Allan Moyle\n","Genre: Comedy, Crime, Drama\n","--------------------------------------------------------------------------------\n","Title: Day of the Dead, Rating: 7.1, User Rating: 3.55, Tags: \n","Director: George A. Romero\n","Genre: Horror, Thriller\n","--------------------------------------------------------------------------------\n","Title: Sergeant York, Rating: 7.7, User Rating: 3.85, Tags: \n","Director: Howard Hawks\n","Genre: Biography, Drama, History, Romance, War\n","--------------------------------------------------------------------------------\n"]}],"source":["import pandas as pd\n","import re\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Input, Attention, Flatten\n","from sklearn.decomposition import PCA\n","from scipy.spatial.distance import euclidean\n","\n","# Load the movie dataset\n","data = pd.read_csv(r'/kaggle/input/movies-updated/movies_with_tags_rating.csv')\n","\n","# Preprocessing\n","df = pd.DataFrame(data)\n","df['overview'] = df['overview'].fillna('')\n","df['cast'] = df['cast'].fillna('')\n","df['director'] = df['director'].fillna('(no data about the director is found)')\n","df['genre'] = df['genre'].fillna('')\n","df['tag'] = df['tag'].fillna('')\n","df['reviews'] = df['reviews'].fillna('')\n","\n","# data cleaning\n","df['overview'] = df['overview'].apply(lambda x: re.sub(r'\\W+', ' ', x.lower()))\n","df['cast'] = df['cast'].apply(lambda x: re.sub(r'\\W+', ' ', x.lower()))\n","df['director'] = df['director'].apply(lambda x: re.sub(r'\\W+', ' ', x.lower()))\n","df['genre'] = df['genre'].apply(lambda x: re.sub(r'\\W+', ' ', x.lower()))\n","df['tag'] = df['tag'].apply(lambda x: re.sub(r'\\W+', ' ', x.lower()))\n","df['reviews'] = df['reviews'].apply(lambda x: re.sub(r'\\W+', ' ', x.lower()))\n","\n","# Feature Weighting\n","df['combined_features'] = (df['overview'] * 7 + ' ' +\n","                           df['cast'] * 1 + ' ' + \n","                           df['director'] * 8 + ' ' + \n","                           df['genre'] * 10 + ' ' + \n","                           df['tag'] * 1 + ' ' + \n","                           df['reviews'] * 1)\n","\n","# Tokenization and padding\n","max_words = 10000\n","max_sequence_len = 500\n","\n","tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(df['combined_features'])\n","sequences = tokenizer.texts_to_sequences(df['combined_features'])\n","padded_sequences = pad_sequences(sequences, maxlen=max_sequence_len, padding='post', truncating='post')\n","\n","# Define LSTM model with Attention mechanism\n","embedding_dim = 100\n","\n","input_layer = Input(shape=(max_sequence_len,))\n","embedding_layer = Embedding(max_words, embedding_dim, input_length=max_sequence_len)(input_layer)\n","lstm_layer_1 = LSTM(128, return_sequences=True)(embedding_layer)\n","dropout_layer_1 = Dropout(0.2)(lstm_layer_1)\n","lstm_layer_2 = LSTM(64, return_sequences=True)(dropout_layer_1)\n","\n","# Attention mechanism\n","attention_layer = Attention()([lstm_layer_2, lstm_layer_2])\n","attention_output = Flatten()(attention_layer)  # Flatten the attention output\n","\n","dense_layer_1 = Dense(32, activation='relu')(attention_output)\n","dense_layer_2 = Dense(16, activation='relu')(dense_layer_1)\n","output_layer = Dense(1, activation='sigmoid')(dense_layer_2)\n","\n","model_with_attention = Model(inputs=input_layer, outputs=output_layer)\n","\n","model_with_attention.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model_with_attention.summary()\n","\n","# Train the LSTM model with Attention mechanism\n","model_with_attention.fit(padded_sequences, np.ones(len(padded_sequences)), epochs=5, batch_size=256)\n","\n","# Generate embeddings from the trained LSTM model with Attention mechanism\n","embedding_model_with_attention = Model(inputs=model_with_attention.input,\n","                                       outputs=model_with_attention.layers[3].output)\n","movie_embeddings_with_attention = embedding_model_with_attention.predict(padded_sequences)\n","\n","# Flatten the LSTM output by averaging over timesteps\n","movie_embeddings_2d_with_attention = np.mean(movie_embeddings_with_attention, axis=1)\n","\n","# Reduce dimensionality of embeddings using PCA\n","pca = PCA(n_components=50)  # Adjust the number of components as needed\n","reduced_embeddings = pca.fit_transform(movie_embeddings_2d_with_attention)\n","\n","# Calculate Euclidean distance based on reduced embeddings\n","def calculate_euclidean_similarity(embeddings):\n","    num_movies = embeddings.shape[0]\n","    euclidean_sim = np.zeros((num_movies, num_movies))\n","    for i in range(num_movies):\n","        for j in range(num_movies):\n","            euclidean_sim[i, j] = euclidean(embeddings[i], embeddings[j])\n","    return euclidean_sim\n","\n","euclidean_sim_lstm_with_attention_reduced = calculate_euclidean_similarity(reduced_embeddings)\n","\n","# Function to clean movie titles (remove special characters and lowercase)\n","def extract_title(title):\n","    if isinstance(title, str):\n","        title_cleaned = title.lower()\n","        title_cleaned = re.sub(r'\\W+', ' ', title_cleaned)\n","        return title_cleaned.strip()\n","    else:\n","        return np.nan\n","\n","# Function to recommend movies based on reduced embeddings with Euclidean distance\n","def recommend_movies_lstm_with_euclidean_reduced(movie_title, euclidean_sim=euclidean_sim_lstm_with_attention_reduced, df=df):\n","    movie_title_clean = extract_title(movie_title)\n","    \n","    # Check if the movie title exists in the dataset\n","    if movie_title_clean in df['title'].apply(extract_title).values:\n","        # Get the index of the movie that matches the title\n","        idx = df.index[df['title'].apply(extract_title) == movie_title_clean][0]\n","        \n","        # Get the pairwise similarity scores of all movies with that movie\n","        sim_scores = list(enumerate(euclidean_sim[idx]))\n","        \n","        # Sort the movies based on similarity scores (ascending order for Euclidean distance)\n","        sim_scores = sorted(sim_scores, key=lambda x: x[1])\n","        \n","        # Get the top 3 most similar movies (excluding the input movie itself)\n","        recommended_movies = []\n","        for score in sim_scores[1:]:\n","            movie_data = df.iloc[score[0]]\n","            recommended_movies.append({\n","                'title': movie_data['title'],\n","                'film_rate': movie_data['film_rate'],\n","                'imdbId': movie_data['imdbId'],\n","                'cover_url': movie_data['cover_url'],\n","                'director': movie_data['director'],\n","                'genre': movie_data['genre'],\n","                'cast': movie_data['cast'],\n","                'overview': movie_data['overview'],\n","                'reviews': movie_data['reviews'],\n","                'tag': movie_data['tag'],\n","                'rating': movie_data['rating']\n","            })\n","            if len(recommended_movies) == 3:  # Limit to top 3 movies\n","                break\n","        \n","        # Return the top 3 most similar movies with all requested details\n","        return recommended_movies\n","    else:\n","        return []  # Return an empty list if the movie is not found\n","\n","# Example usage with reduced embeddings and Euclidean distance\n","test_movie_heat = 'heat'\n","recommended_movies_lstm_with_euclidean_reduced_heat = recommend_movies_lstm_with_euclidean_reduced(test_movie_heat)\n","\n","if not recommended_movies_lstm_with_euclidean_reduced_heat:\n","    print(f\"'{test_movie_heat}' is not listed in our database.\")\n","else:\n","    print(f\"Movies recommended based on '{test_movie_heat}':\")\n","    for movie in recommended_movies_lstm_with_euclidean_reduced_heat:\n","        print(f\"Title: {movie['title']}, Rating: {movie['film_rate']}, User Rating: {movie['rating']}, Tags: {movie['tag']}\")\n","        print(f\"Director: {movie['director']}\")\n","        print(f\"Genre: {movie['genre']}\")\n","        print(\"-\" * 80)\n","\n","test_movie_interstellar = 'interstellar'\n","recommended_movies_lstm_with_euclidean_reduced_interstellar = recommend_movies_lstm_with_euclidean_reduced(test_movie_interstellar)\n","\n","if not recommended_movies_lstm_with_euclidean_reduced_interstellar:\n","    print(f\"'{test_movie_interstellar}' is not listed in our database.\")\n","else:\n","    print(f\"Movies recommended based on '{test_movie_interstellar}':\")\n","    for movie in recommended_movies_lstm_with_euclidean_reduced_interstellar:\n","        print(f\"Title: {movie['title']}, Rating: {movie['film_rate']}, User Rating: {movie['rating']}, Tags: {movie['tag']}\")\n","        print(f\"Director: {movie['director']}\")\n","        print(f\"Genre: {movie['genre']}\")\n","        print(\"-\" * 80)\n"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T02:03:24.949897Z","iopub.status.busy":"2024-09-17T02:03:24.949479Z","iopub.status.idle":"2024-09-17T02:24:53.037452Z","shell.execute_reply":"2024-09-17T02:24:53.036445Z","shell.execute_reply.started":"2024-09-17T02:03:24.949858Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_51\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"functional_51\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_14      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding_14        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> │ input_layer_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span> │ embedding_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dropout_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> │ dropout_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dropout_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │ dropout_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ attention_14        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ lstm_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ flatten_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19200</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,228,864</span> │ flatten_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_14      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding_14        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │  \u001b[38;5;34m1,000,000\u001b[0m │ input_layer_14[\u001b[38;5;34m0\u001b[0m… │\n","│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_28 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │    \u001b[38;5;34m365,568\u001b[0m │ embedding_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dropout_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ lstm_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n","│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_29 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m197,120\u001b[0m │ dropout_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dropout_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ lstm_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n","│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_30 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m49,408\u001b[0m │ dropout_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ attention_14        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ lstm_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n","│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ lstm_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ flatten_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19200\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ attention_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n","│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_41 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │  \u001b[38;5;34m1,228,864\u001b[0m │ flatten_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_42 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_43 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dense_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,843,073</span> (10.85 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,843,073\u001b[0m (10.85 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,843,073</span> (10.85 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,843,073\u001b[0m (10.85 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 131ms/step - accuracy: 0.9909 - loss: 0.1125\n","Epoch 2/5\n","\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n","Epoch 3/5\n","\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n","Epoch 4/5\n","\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n","Epoch 5/5\n","\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n","\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n","Movies recommended based on 'heat':\n","Title: Son of a Gun, Rating: 6.4, User Rating: 3.2, Tags: \n","Director: julius avery\n","Genre: action crime drama thriller\n","Title: Because I Said So, Rating: 5.6, User Rating: 2.8, Tags: \n","Director: michael lehmann\n","Genre: comedy romance\n","Title: About Adam, Rating: 5.8, User Rating: 2.9, Tags: \n","Director: gerard stembridge\n","Genre: comedy romance\n"]}],"source":["import pandas as pd\n","import re\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Input, Attention, Flatten\n","from sklearn.decomposition import PCA\n","from scipy.spatial.distance import euclidean\n","\n","# Load the movie dataset\n","data = pd.read_csv(r'/kaggle/input/movies-updated/movies_with_tags_rating.csv')\n","\n","# Preprocessing\n","df = pd.DataFrame(data)\n","df['overview'] = df['overview'].fillna('')\n","df['cast'] = df['cast'].fillna('')\n","df['director'] = df['director'].fillna('(no data about the director is found)')\n","df['genre'] = df['genre'].fillna('')\n","df['tag'] = df['tag'].fillna('')\n","df['reviews'] = df['reviews'].fillna('')\n","\n","# Clean text data\n","df['overview'] = df['overview'].apply(lambda x: re.sub(r'\\W+', ' ', x.lower()))\n","df['cast'] = df['cast'].apply(lambda x: re.sub(r'\\W+', ' ', x.lower()))\n","df['director'] = df['director'].apply(lambda x: re.sub(r'\\W+', ' ', x.lower()))\n","df['genre'] = df['genre'].apply(lambda x: re.sub(r'\\W+', ' ', x.lower()))\n","df['tag'] = df['tag'].apply(lambda x: re.sub(r'\\W+', ' ', x.lower()))\n","df['reviews'] = df['reviews'].apply(lambda x: re.sub(r'\\W+', ' ', x.lower()))\n","\n","# Feature Weighting\n","df['combined_features'] = (df['overview'] * 7 + ' ' +\n","                           df['cast'] * 2 + ' ' + \n","                           df['director'] * 5 + ' ' + \n","                           df['genre'] * 6 + ' ' + \n","                           df['tag'] * 1 + ' ' + \n","                           df['reviews'] * 1)\n","\n","# Tokenization and padding\n","max_words = 10000\n","max_sequence_len = 300\n","\n","tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(df['combined_features'])\n","sequences = tokenizer.texts_to_sequences(df['combined_features'])\n","padded_sequences = pad_sequences(sequences, maxlen=max_sequence_len, padding='post', truncating='post')\n","\n","# Define LSTM model with Attention mechanism\n","embedding_dim = 100\n","\n","input_layer = Input(shape=(max_sequence_len,))\n","embedding_layer = Embedding(max_words, embedding_dim, input_length=max_sequence_len)(input_layer)\n","lstm_layer_1 = LSTM(256, return_sequences=True)(embedding_layer)\n","dropout_layer_1 = Dropout(0.3)(lstm_layer_1)\n","lstm_layer_2 = LSTM(128, return_sequences=True)(dropout_layer_1)\n","dropout_layer_2 = Dropout(0.3)(lstm_layer_2)\n","lstm_layer_3 = LSTM(64, return_sequences=True)(dropout_layer_2)\n","\n","# Attention mechanism\n","attention_layer = Attention()([lstm_layer_3, lstm_layer_3])\n","attention_output = Flatten()(attention_layer)  # Flatten the attention output\n","\n","dense_layer_1 = Dense(64, activation='relu')(attention_output)\n","dense_layer_2 = Dense(32, activation='relu')(dense_layer_1)\n","output_layer = Dense(1, activation='sigmoid')(dense_layer_2)\n","\n","model_with_attention = Model(inputs=input_layer, outputs=output_layer)\n","\n","model_with_attention.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model_with_attention.summary()\n","\n","# Train the LSTM model with Attention mechanism\n","model_with_attention.fit(padded_sequences, np.ones(len(padded_sequences)), epochs=5, batch_size=256)\n","\n","# Generate embeddings from the trained LSTM model with Attention mechanism\n","embedding_model_with_attention = Model(inputs=model_with_attention.input,\n","                                       outputs=model_with_attention.layers[3].output)\n","movie_embeddings_with_attention = embedding_model_with_attention.predict(padded_sequences)\n","\n","# Flatten the LSTM output by averaging over timesteps\n","movie_embeddings_2d_with_attention = np.mean(movie_embeddings_with_attention, axis=1)\n","\n","# Reduce dimensionality of embeddings using PCA\n","pca = PCA(n_components=50)  # Adjust the number of components as needed\n","reduced_embeddings = pca.fit_transform(movie_embeddings_2d_with_attention)\n","\n","# Calculate Euclidean distance based on reduced embeddings\n","def calculate_euclidean_similarity(embeddings):\n","    num_movies = embeddings.shape[0]\n","    euclidean_sim = np.zeros((num_movies, num_movies))\n","    for i in range(num_movies):\n","        for j in range(num_movies):\n","            euclidean_sim[i, j] = euclidean(embeddings[i], embeddings[j])\n","    return euclidean_sim\n","\n","euclidean_sim_lstm_with_attention_reduced = calculate_euclidean_similarity(reduced_embeddings)\n","\n","# Function to clean movie titles (remove special characters and lowercase)\n","def extract_title(title):\n","    if isinstance(title, str):\n","        title_cleaned = title.lower()\n","        title_cleaned = re.sub(r'\\W+', ' ', title_cleaned)\n","        return title_cleaned.strip()\n","    else:\n","        return np.nan\n","\n","# Function to recommend movies based on reduced embeddings with Euclidean distance\n","def recommend_movies_lstm_with_euclidean_reduced(movie_title, euclidean_sim=euclidean_sim_lstm_with_attention_reduced, df=df):\n","    movie_title_clean = extract_title(movie_title)\n","    \n","    # Check if the movie title exists in the dataset\n","    if movie_title_clean in df['title'].apply(extract_title).values:\n","        # Get the index of the movie that matches the title\n","        idx = df.index[df['title'].apply(extract_title) == movie_title_clean][0]\n","        \n","        # Get the pairwise similarity scores of all movies with that movie\n","        sim_scores = list(enumerate(euclidean_sim[idx]))\n","        \n","        # Sort the movies based on similarity scores (ascending order for Euclidean distance)\n","        sim_scores = sorted(sim_scores, key=lambda x: x[1])\n","        \n","        # Get the top 3 most similar movies (excluding the input movie itself)\n","        recommended_movies = []\n","        for score in sim_scores[1:]:\n","            movie_data = df.iloc[score[0]]\n","            recommended_movies.append({\n","                'title': movie_data['title'],\n","                'film_rate': movie_data['film_rate'],\n","                'imdbId': movie_data['imdbId'],\n","                'cover_url': movie_data['cover_url'],\n","                'director': movie_data['director'],\n","                'genre': movie_data['genre'],\n","                'cast': movie_data['cast'],\n","                'overview': movie_data['overview'],\n","                'reviews': movie_data['reviews'],\n","                'tag': movie_data['tag'],\n","                'rating': movie_data['rating']\n","            })\n","            if len(recommended_movies) == 3:  # Limit to top 3 movies\n","                break\n","        \n","        # Return the top 3 most similar movies with all requested details\n","        return recommended_movies\n","    else:\n","        return []  # Return an empty list if the movie is not found\n","\n","# Example usage with reduced embeddings and Euclidean distance\n","test_movie_heat = 'heat'\n","recommended_movies_lstm_with_euclidean_reduced_heat = recommend_movies_lstm_with_euclidean_reduced(test_movie_heat)\n","\n","if not recommended_movies_lstm_with_euclidean_reduced_heat:\n","    print(f\"'{test_movie_heat}' is not listed in our database.\")\n","else:\n","    print(f\"Movies recommended based on '{test_movie_heat}':\")\n","    for movie in recommended_movies_lstm_with_euclidean_reduced_heat:\n","        print(f\"Title: {movie['title']}, Rating: {movie['film_rate']}, User Rating: {movie['rating']}, Tags: {movie['tag']}\")\n","        print(f\"Director: {movie['director']}\")\n","        print(f\"Genre: {movie['genre']}\")\n"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T02:28:46.689810Z","iopub.status.busy":"2024-09-17T02:28:46.689344Z","iopub.status.idle":"2024-09-17T02:54:11.974270Z","shell.execute_reply":"2024-09-17T02:54:11.973294Z","shell.execute_reply.started":"2024-09-17T02:28:46.689768Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_55\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"functional_55\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_15      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding_15        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> │ input_layer_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span> │ embedding_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dropout_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> │ dropout_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dropout_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │ dropout_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ attention_15        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ lstm_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ flatten_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19200</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,228,864</span> │ flatten_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_15      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding_15        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │  \u001b[38;5;34m1,000,000\u001b[0m │ input_layer_15[\u001b[38;5;34m0\u001b[0m… │\n","│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_31 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │    \u001b[38;5;34m365,568\u001b[0m │ embedding_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dropout_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ lstm_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n","│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_32 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m197,120\u001b[0m │ dropout_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dropout_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ lstm_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n","│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_33 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m49,408\u001b[0m │ dropout_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ attention_15        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ lstm_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n","│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ lstm_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ flatten_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19200\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ attention_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n","│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_44 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │  \u001b[38;5;34m1,228,864\u001b[0m │ flatten_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_45 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_46 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dense_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,843,073</span> (10.85 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,843,073\u001b[0m (10.85 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,843,073</span> (10.85 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,843,073\u001b[0m (10.85 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 163ms/step - accuracy: 0.9991 - loss: 6.5478 - val_accuracy: 1.0000 - val_loss: 2.4152\n","Epoch 2/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 1.8413 - val_accuracy: 1.0000 - val_loss: 0.7248\n","Epoch 3/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.5669 - val_accuracy: 1.0000 - val_loss: 0.2569\n","Epoch 4/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.2104 - val_accuracy: 1.0000 - val_loss: 0.1135\n","Epoch 5/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0966 - val_accuracy: 1.0000 - val_loss: 0.0586\n","Epoch 6/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0510 - val_accuracy: 1.0000 - val_loss: 0.0330\n","Epoch 7/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0290 - val_accuracy: 1.0000 - val_loss: 0.0193\n","Epoch 8/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0171 - val_accuracy: 1.0000 - val_loss: 0.0115\n","Epoch 9/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 1.0000 - val_loss: 0.0070\n","Epoch 10/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 1.0000 - val_loss: 0.0045\n","Epoch 11/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 0.0030\n","Epoch 12/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 0.0022\n","Epoch 13/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0017\n","Epoch 14/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0014\n","Epoch 15/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0013\n","Epoch 16/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0012\n","Epoch 17/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0011\n","Epoch 18/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0010\n","Epoch 19/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 9.7855e-04\n","Epoch 20/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 9.6354e-04 - val_accuracy: 1.0000 - val_loss: 9.2033e-04\n","Epoch 21/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 9.0659e-04 - val_accuracy: 1.0000 - val_loss: 8.6751e-04\n","Epoch 22/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 8.5532e-04 - val_accuracy: 1.0000 - val_loss: 8.1784e-04\n","Epoch 23/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 8.0581e-04 - val_accuracy: 1.0000 - val_loss: 7.7031e-04\n","Epoch 24/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 7.5884e-04 - val_accuracy: 1.0000 - val_loss: 7.2514e-04\n","Epoch 25/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 7.1453e-04 - val_accuracy: 1.0000 - val_loss: 6.8379e-04\n","Epoch 26/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 6.7428e-04 - val_accuracy: 1.0000 - val_loss: 6.4685e-04\n","Epoch 27/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 6.3839e-04 - val_accuracy: 1.0000 - val_loss: 6.1397e-04\n","Epoch 28/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 6.0640e-04 - val_accuracy: 1.0000 - val_loss: 5.8448e-04\n","Epoch 29/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 5.7765e-04 - val_accuracy: 1.0000 - val_loss: 5.5777e-04\n","Epoch 30/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 5.5152e-04 - val_accuracy: 1.0000 - val_loss: 5.3328e-04\n","Epoch 31/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 5.2751e-04 - val_accuracy: 1.0000 - val_loss: 5.1060e-04\n","Epoch 32/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 5.0523e-04 - val_accuracy: 1.0000 - val_loss: 4.8942e-04\n","Epoch 33/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 4.8437e-04 - val_accuracy: 1.0000 - val_loss: 4.6949e-04\n","Epoch 34/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 4.6472e-04 - val_accuracy: 1.0000 - val_loss: 4.5063e-04\n","Epoch 35/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 4.4610e-04 - val_accuracy: 1.0000 - val_loss: 4.3270e-04\n","Epoch 36/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 4.2838e-04 - val_accuracy: 1.0000 - val_loss: 4.1560e-04\n","Epoch 37/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 4.1147e-04 - val_accuracy: 1.0000 - val_loss: 3.9924e-04\n","Epoch 38/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 3.9528e-04 - val_accuracy: 1.0000 - val_loss: 3.8356e-04\n","Epoch 39/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 3.7977e-04 - val_accuracy: 1.0000 - val_loss: 3.6852e-04\n","Epoch 40/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 3.6487e-04 - val_accuracy: 1.0000 - val_loss: 3.5405e-04\n","Epoch 41/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 3.5055e-04 - val_accuracy: 1.0000 - val_loss: 3.4014e-04\n","Epoch 42/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 3.3676e-04 - val_accuracy: 1.0000 - val_loss: 3.2681e-04\n","Epoch 43/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 3.2376e-04 - val_accuracy: 1.0000 - val_loss: 3.1383e-04\n","Epoch 44/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 3.1068e-04 - val_accuracy: 1.0000 - val_loss: 3.0132e-04\n","Epoch 45/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 2.9831e-04 - val_accuracy: 1.0000 - val_loss: 2.8943e-04\n","Epoch 46/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 2.8631e-04 - val_accuracy: 1.0000 - val_loss: 2.7747e-04\n","Epoch 47/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 2.7461e-04 - val_accuracy: 1.0000 - val_loss: 2.6608e-04\n","Epoch 48/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 2.6332e-04 - val_accuracy: 1.0000 - val_loss: 2.5502e-04\n","Epoch 49/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 2.5230e-04 - val_accuracy: 1.0000 - val_loss: 2.4421e-04\n","Epoch 50/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 2.4156e-04 - val_accuracy: 1.0000 - val_loss: 2.3368e-04\n","\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n","Movies recommended based on 'heat':\n","Title: In the Land of Women, Rating: 6.4, User Rating: 3.2, Tags: \n","Director: jonathan kasdan\n","Genre: comedy drama romance\n","--------------------------------------------------------------------------------\n","Title: Come Back, Little Sheba, Rating: 7.5, User Rating: 3.75, Tags: \n","Director: daniel mann\n","Genre: drama romance\n","--------------------------------------------------------------------------------\n","Title: Knocked Up, Rating: 6.9, User Rating: 3.45, Tags: \n","Director: judd apatow\n","Genre: comedy romance\n","--------------------------------------------------------------------------------\n","Movies recommended based on 'interstellar':\n","Title: Winnie-the-Pooh, Rating: 8.2, User Rating: 4.1, Tags: \n","Director: fyodor khitruk\n","Genre: animation short comedy family\n","--------------------------------------------------------------------------------\n","Title: The Doctor, the Widow and the Wardrobe, Rating: 7.1, User Rating: 3.55, Tags: \n","Director: farren blackburn\n","Genre: adventure drama sci fi\n","--------------------------------------------------------------------------------\n","Title: The Mask of Zorro, Rating: 6.8, User Rating: 3.4, Tags: \n","Director: martin campbell\n","Genre: action adventure comedy romance thriller western\n","--------------------------------------------------------------------------------\n"]}],"source":["import pandas as pd\n","import re\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Input, Attention, Flatten\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.decomposition import PCA\n","from scipy.spatial.distance import euclidean\n","\n","# Load the movie dataset\n","data = pd.read_csv(r'/kaggle/input/movies-updated/movies_with_tags_rating.csv')\n","\n","# Preprocessing\n","df = pd.DataFrame(data)\n","df['overview'] = df['overview'].fillna('')\n","df['cast'] = df['cast'].fillna('')\n","df['director'] = df['director'].fillna('(no data about the director is found)')\n","df['genre'] = df['genre'].fillna('')\n","df['tag'] = df['tag'].fillna('')\n","df['reviews'] = df['reviews'].fillna('')\n","\n","# Clean text data\n","df['overview'] = df['overview'].apply(lambda x: re.sub(r'\\W+', ' ', x.lower()))\n","df['cast'] = df['cast'].apply(lambda x: re.sub(r'\\W+', ' ', x.lower()))\n","df['director'] = df['director'].apply(lambda x: re.sub(r'\\W+', ' ', x.lower()))\n","df['genre'] = df['genre'].apply(lambda x: re.sub(r'\\W+', ' ', x.lower()))\n","df['tag'] = df['tag'].apply(lambda x: re.sub(r'\\W+', ' ', x.lower()))\n","df['reviews'] = df['reviews'].apply(lambda x: re.sub(r'\\W+', ' ', x.lower()))\n","\n","# Feature Weighting\n","df['combined_features'] = (df['overview'] * 7 + ' ' +\n","                           df['cast'] * 2 + ' ' + \n","                           df['director'] * 5 + ' ' + \n","                           df['genre'] * 6 + ' ' + \n","                           df['tag'] * 1 + ' ' + \n","                           df['reviews'] * 1)\n","\n","# Tokenization and padding\n","max_words = 10000\n","max_sequence_len = 300\n","\n","tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(df['combined_features'])\n","sequences = tokenizer.texts_to_sequences(df['combined_features'])\n","padded_sequences = pad_sequences(sequences, maxlen=max_sequence_len, padding='post', truncating='post')\n","\n","# Define LSTM model with Attention mechanism\n","embedding_dim = 100\n","\n","input_layer = Input(shape=(max_sequence_len,))\n","embedding_layer = Embedding(max_words, embedding_dim, input_length=max_sequence_len)(input_layer)\n","lstm_layer_1 = LSTM(256, return_sequences=True, kernel_regularizer=l2(0.01))(embedding_layer)\n","dropout_layer_1 = Dropout(0.5)(lstm_layer_1)\n","lstm_layer_2 = LSTM(128, return_sequences=True, kernel_regularizer=l2(0.01))(dropout_layer_1)\n","dropout_layer_2 = Dropout(0.5)(lstm_layer_2)\n","lstm_layer_3 = LSTM(64, return_sequences=True, kernel_regularizer=l2(0.01))(dropout_layer_2)\n","\n","# Attention mechanism\n","attention_layer = Attention()([lstm_layer_3, lstm_layer_3])\n","attention_output = Flatten()(attention_layer)  # Flatten the attention output\n","\n","dense_layer_1 = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(attention_output)\n","dense_layer_2 = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(dense_layer_1)\n","output_layer = Dense(1, activation='sigmoid')(dense_layer_2)\n","\n","model_with_attention = Model(inputs=input_layer, outputs=output_layer)\n","\n","model_with_attention.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model_with_attention.summary()\n","\n","# Early stopping callback\n","early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","\n","# Train the LSTM model with Attention mechanism\n","model_with_attention.fit(padded_sequences, np.ones(len(padded_sequences)), epochs=20, batch_size=256, validation_split=0.2, callbacks=[early_stopping])\n","\n","# Generate embeddings from the trained LSTM model with Attention mechanism\n","embedding_model_with_attention = Model(inputs=model_with_attention.input,\n","                                       outputs=model_with_attention.layers[3].output)\n","movie_embeddings_with_attention = embedding_model_with_attention.predict(padded_sequences)\n","\n","# Flatten the LSTM output by averaging over timesteps\n","movie_embeddings_2d_with_attention = np.mean(movie_embeddings_with_attention, axis=1)\n","\n","# Reduce dimensionality of embeddings using PCA\n","pca = PCA(n_components=50)  # Adjust the number of components as needed\n","reduced_embeddings = pca.fit_transform(movie_embeddings_2d_with_attention)\n","\n","# Calculate Euclidean distance based on reduced embeddings\n","def calculate_euclidean_similarity(embeddings):\n","    num_movies = embeddings.shape[0]\n","    euclidean_sim = np.zeros((num_movies, num_movies))\n","    for i in range(num_movies):\n","        for j in range(num_movies):\n","            euclidean_sim[i, j] = euclidean(embeddings[i], embeddings[j])\n","    return euclidean_sim\n","\n","euclidean_sim_lstm_with_attention_reduced = calculate_euclidean_similarity(reduced_embeddings)\n","\n","# Function to clean movie titles (remove special characters and lowercase)\n","def extract_title(title):\n","    if isinstance(title, str):\n","        title_cleaned = title.lower()\n","        title_cleaned = re.sub(r'\\W+', ' ', title_cleaned)\n","        return title_cleaned.strip()\n","    else:\n","        return np.nan\n","\n","# Function to recommend movies based on reduced embeddings with Euclidean distance\n","def recommend_movies_lstm_with_euclidean_reduced(movie_title, euclidean_sim=euclidean_sim_lstm_with_attention_reduced, df=df):\n","    movie_title_clean = extract_title(movie_title)\n","    \n","    # Check if the movie title exists in the dataset\n","    if movie_title_clean in df['title'].apply(extract_title).values:\n","        # Get the index of the movie that matches the title\n","        idx = df.index[df['title'].apply(extract_title) == movie_title_clean][0]\n","        \n","        # Get the pairwise similarity scores of all movies with that movie\n","        sim_scores = list(enumerate(euclidean_sim[idx]))\n","        \n","        # Sort the movies based on similarity scores (ascending order for Euclidean distance)\n","        sim_scores = sorted(sim_scores, key=lambda x: x[1])\n","        \n","        # Get the top 3 most similar movies (excluding the input movie itself)\n","        recommended_movies = []\n","        for score in sim_scores[1:]:\n","            movie_data = df.iloc[score[0]]\n","            recommended_movies.append({\n","                'title': movie_data['title'],\n","                'film_rate': movie_data['film_rate'],\n","                'imdbId': movie_data['imdbId'],\n","                'cover_url': movie_data['cover_url'],\n","                'director': movie_data['director'],\n","                'genre': movie_data['genre'],\n","                'cast': movie_data['cast'],\n","                'overview': movie_data['overview'],\n","                'reviews': movie_data['reviews'],\n","                'tag': movie_data['tag'],\n","                'rating': movie_data['rating']\n","            })\n","            if len(recommended_movies) == 3:  # Limit to top 3 movies\n","                break\n","        \n","        # Return the top 3 most similar movies with all requested details\n","        return recommended_movies\n","    else:\n","        return []  # Return an empty list if the movie is not found\n","\n","# Example usage with reduced embeddings and Euclidean distance\n","test_movie_heat = 'heat'\n","recommended_movies_lstm_with_euclidean_reduced_heat = recommend_movies_lstm_with_euclidean_reduced(test_movie_heat)\n","\n","if not recommended_movies_lstm_with_euclidean_reduced_heat:\n","    print(f\"'{test_movie_heat}' is not listed in our database.\")\n","else:\n","    print(f\"Movies recommended based on '{test_movie_heat}':\")\n","    for movie in recommended_movies_lstm_with_euclidean_reduced_heat:\n","        print(f\"Title: {movie['title']}, Rating: {movie['film_rate']}, User Rating: {movie['rating']}, Tags: {movie['tag']}\")\n","        print(f\"Director: {movie['director']}\")\n","        print(f\"Genre: {movie['genre']}\")\n","        print(\"-\" * 80)\n","\n","test_movie_interstellar = 'interstellar'\n","recommended_movies_lstm_with_euclidean_reduced_interstellar = recommend_movies_lstm_with_euclidean_reduced(test_movie_interstellar)\n","\n","if not recommended_movies_lstm_with_euclidean_reduced_interstellar:\n","    print(f\"'{test_movie_interstellar}' is not listed in our database.\")\n","else:\n","    print(f\"Movies recommended based on '{test_movie_interstellar}':\")\n","    for movie in recommended_movies_lstm_with_euclidean_reduced_interstellar:\n","        print(f\"Title: {movie['title']}, Rating: {movie['film_rate']}, User Rating: {movie['rating']}, Tags: {movie['tag']}\")\n","        print(f\"Director: {movie['director']}\")\n","        print(f\"Genre: {movie['genre']}\")\n","        print(\"-\" * 80)\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5681965,"sourceId":9369105,"sourceType":"datasetVersion"},{"datasetId":5687713,"sourceId":9376607,"sourceType":"datasetVersion"},{"datasetId":5687719,"sourceId":9376615,"sourceType":"datasetVersion"},{"datasetId":5701159,"sourceId":9394033,"sourceType":"datasetVersion"},{"datasetId":5717842,"sourceId":9415106,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
